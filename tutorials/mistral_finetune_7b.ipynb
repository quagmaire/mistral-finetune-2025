{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quagmaire/mistral-finetune-2025/blob/main/tutorials/mistral_finetune_7b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyuOCYM92LJb"
      },
      "source": [
        "# Getting Started with Fine-Tuning Mistral 7B\n",
        "\n",
        "This notebook shows you a simple example of how to LoRA finetune Mistral 7B. You can run this notebook in Google Colab with Pro + account with A100 and 40GB RAM.\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mistralai/mistral-finetune/blob/main/tutorials/mistral_finetune_7b.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "\n",
        "Check out `mistral-finetune` Github repo to learn more: https://github.com/mistralai/mistral-finetune/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpyPeNYr8TLk",
        "outputId": "c71eda25-3e40-4c50-892d-795cf56addf5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create --name myenv python=3.10"
      ],
      "metadata": {
        "id": "qSb131CE8V8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1873eb8b-b9b5-42ed-fde9-13165121b74e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bzip2-1.0.8                |       hda65f42_8         254 KB  conda-forge\n",
            "    ca-certificates-2025.8.3   |       hbd8a1cb_0         151 KB  conda-forge\n",
            "    ld_impl_linux-64-2.44      |       ha97dd6f_2         730 KB  conda-forge\n",
            "    libexpat-2.7.1             |       hecca717_0          73 KB  conda-forge\n",
            "    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n",
            "    libgcc-15.1.0              |       h767d61c_5         805 KB  conda-forge\n",
            "    libgcc-ng-15.1.0           |       h69a702a_5          29 KB  conda-forge\n",
            "    libgomp-15.1.0             |       h767d61c_5         437 KB  conda-forge\n",
            "    liblzma-5.8.1              |       hb9d3cd8_2         110 KB  conda-forge\n",
            "    libnsl-2.0.1               |       hb9d3cd8_1          33 KB  conda-forge\n",
            "    libsqlite-3.50.4           |       h0c1763c_0         911 KB  conda-forge\n",
            "    libuuid-2.41.2             |       he9a06e4_0          36 KB  conda-forge\n",
            "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
            "    openssl-3.5.3              |       h26f9b46_1         3.0 MB  conda-forge\n",
            "    pip-25.2                   |     pyh8b19718_0         1.1 MB  conda-forge\n",
            "    python-3.10.18             |hd6af730_0_cpython        23.9 MB  conda-forge\n",
            "    readline-8.2               |       h8c095d6_2         276 KB  conda-forge\n",
            "    setuptools-80.9.0          |     pyhff2d567_0         731 KB  conda-forge\n",
            "    tk-8.6.13                  |noxft_hd72426e_102         3.1 MB  conda-forge\n",
            "    tzdata-2025b               |       h78e105d_0         120 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        36.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hda65f42_8 \n",
            "  ca-certificates    conda-forge/noarch::ca-certificates-2025.8.3-hbd8a1cb_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.44-ha97dd6f_2 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.7.1-hecca717_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1 \n",
            "  libgcc             conda-forge/linux-64::libgcc-15.1.0-h767d61c_5 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.1.0-h69a702a_5 \n",
            "  libgomp            conda-forge/linux-64::libgomp-15.1.0-h767d61c_5 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_2 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hb9d3cd8_1 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.50.4-h0c1763c_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.41.2-he9a06e4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.5.3-h26f9b46_1 \n",
            "  pip                conda-forge/noarch::pip-25.2-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.18-hd6af730_0_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
            "  setuptools         conda-forge/noarch::setuptools-80.9.0-pyhff2d567_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_hd72426e_102 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.18       | 23.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 730 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.2       | 36 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :   4% 0.03598419110723426/1 [00:00<00:02,  2.78s/it]\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | :  39% 0.387536970392042/1 [00:00<00:00,  3.87it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | : 100% 1.0/1 [00:00<00:00,  9.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | : 100% 1.0/1 [00:00<00:00,  9.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  8.36it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  8.36it/s]\u001b[A\u001b[A\u001b[A\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.58it/s]\u001b[A\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.58it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | :   2% 0.019878887296755243/1 [00:00<00:08,  8.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | :   2% 0.021880692532465797/1 [00:00<00:07,  8.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | : 100% 1.0/1 [00:00<00:00,  9.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  25% 0.2518893377506398/1 [00:00<00:00,  1.41it/s] \n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.04it/s]              \u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | : 100% 1.0/1 [00:00<00:00,  8.40s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:00<00:00,  8.16s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 730 KB    | :   2% 0.021928427454434/1 [00:00<00:10, 11.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:00<00:00, 10.33s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   6% 0.05800056641178136/1 [00:00<00:04,  4.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | :   4% 0.03663562268707445/1 [00:00<00:07,  7.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  44% 0.4429326796290472/1 [00:00<00:00,  1.63it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:00<00:00,  4.66s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | :   6% 0.06293284576766625/1 [00:00<00:04,  4.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:00<00:00,  4.68s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | : 100% 1.0/1 [00:00<00:00,  7.51s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :  13% 0.1332379155552664/1 [00:00<00:02,  2.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | :  11% 0.10611261512156578/1 [00:00<00:02,  3.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:00<00:00,  2.42s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | : 100% 1.0/1 [00:00<00:00,  3.07s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | :  22% 0.2190052265041237/1 [00:00<00:01,  1.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :  15% 0.1451272875440679/1 [00:00<00:02,  2.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:00<00:00,  2.48s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | : 100% 1.0/1 [00:00<00:00,  1.64s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :  29% 0.2852715337871955/1 [00:00<00:00,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.2       | 36 KB     | :  44% 0.441201023293389/1 [00:00<00:00,  1.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:00<00:00,  1.32s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  64% 0.6352845375477176/1 [00:00<00:00,  1.75it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | :  49% 0.4857252972043521/1 [00:00<00:00,  1.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:00<00:00,  1.18it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  93% 0.9290463885867756/1 [00:00<00:00,  2.05it/s]\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  5.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | : 100% 1.0/1 [00:00<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | : 100% 1.0/1 [00:00<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  8.36it/s]\u001b[A\u001b[A\u001b[A\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  6.58it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 730 KB    | : 100% 1.0/1 [00:01<00:00,  1.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | : 100% 1.0/1 [00:01<00:00,  2.05it/s]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:01<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:01<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:01<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:01<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | : 100% 1.0/1 [00:01<00:00,  1.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | : 100% 1.0/1 [00:01<00:00,  1.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:01<00:00,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:01<00:00,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | : 100% 1.0/1 [00:01<00:00,  1.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | : 100% 1.0/1 [00:01<00:00,  1.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:01<00:00,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:01<00:00,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.2       | 36 KB     | : 100% 1.0/1 [00:01<00:00,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.2       | 36 KB     | : 100% 1.0/1 [00:01<00:00,  1.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:01<00:00,  1.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:01<00:00,  1.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:01<00:00,  1.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:01<00:00,  1.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:02<00:00,  2.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | : 100% 1.0/1 [00:02<00:00,  2.05it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "import sys\n",
        "print(sys.version)\n",
        "EOF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd5S9ctcCOFJ",
        "outputId": "8f082100-4766-4d30-c023-006a0775f9f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxr8mv-17GfB"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Clone the `mistral-finetune` repo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIj3IlIeVDIb",
        "outputId": "783964ef-3f9a-49fa-cd11-e826861e3884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'mistral-finetune'...\n",
            "remote: Enumerating objects: 472, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 472 (delta 211), reused 159 (delta 159), pack-reused 223 (from 2)\u001b[K\n",
            "Receiving objects: 100% (472/472), 243.32 KiB | 2.56 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/mistralai/mistral-finetune.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQPd_pGT7WiY"
      },
      "source": [
        "Install all required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuTOGipl7BS7",
        "outputId": "6ffceb96-de34-465c-96a1-d577b405b818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire (from -r /content/mistral-finetune/requirements.txt (line 1))\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting simple-parsing (from -r /content/mistral-finetune/requirements.txt (line 2))\n",
            "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pyyaml (from -r /content/mistral-finetune/requirements.txt (line 3))\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting mistral-common>=1.3.1 (from -r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting safetensors (from -r /content/mistral-finetune/requirements.txt (line 5))\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorboard (from -r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm (from -r /content/mistral-finetune/requirements.txt (line 7))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting torch==2.2 (from -r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting triton==2.2 (from -r /content/mistral-finetune/requirements.txt (line 10))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting xformers==0.0.24 (from -r /content/mistral-finetune/requirements.txt (line 11))\n",
            "  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting filelock (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting numpy (from xformers==0.0.24->-r /content/mistral-finetune/requirements.txt (line 11))\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting termcolor (from fire->-r /content/mistral-finetune/requirements.txt (line 1))\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing->-r /content/mistral-finetune/requirements.txt (line 2))\n",
            "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pydantic<3.0,>=2.7 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting tiktoken>=0.7.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting requests>=2.0.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=2.7->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0,>=2.7->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0,>=2.7->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading grpcio-1.75.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting packaging (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (80.9.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading grpcio-1.75.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
            "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "Downloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (152 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Downloading rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.9/789.9 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, termcolor, tensorboard-data-server, sympy, safetensors, rpds-py, regex, pyyaml, pycountry, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, markdown, idna, fsspec, filelock, docstring-parser, charset_normalizer, certifi, attrs, annotated-types, absl-py, werkzeug, typing-inspection, triton, simple-parsing, requests, referencing, pydantic-core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, grpcio, fire, tiktoken, tensorboard, pydantic, nvidia-cusolver-cu12, jsonschema-specifications, torch, pydantic-extra-types, jsonschema, xformers, mistral-common\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/59\u001b[0m [mistral-common]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 absl-py-2.3.1 annotated-types-0.7.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 docstring-parser-0.17.0 filelock-3.19.1 fire-0.7.1 fsspec-2025.9.0 grpcio-1.75.0 idna-3.10 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 markdown-3.9 mistral-common-1.8.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 packaging-25.0 pillow-11.3.0 protobuf-6.32.1 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 pyyaml-6.0.2 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 rpds-py-0.27.1 safetensors-0.6.2 simple-parsing-0.1.7 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 termcolor-3.1.0 tiktoken-0.11.0 torch-2.2.0 tqdm-4.67.1 triton-2.2.0 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0 werkzeug-3.1.3 xformers-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!conda run --live-stream -n myenv python -m pip install -r /content/mistral-finetune/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgdIAi257jLo"
      },
      "source": [
        "## Model download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fa1zgi8Mpr",
        "outputId": "bfb0c5cb-a232-4889-84a5-7d7124cb3f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filelock (from huggingface_hub)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
            "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)\n",
            "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: typing-extensions, pyyaml, hf-xet, fsspec, filelock, huggingface_hub\n",
            "Successfully installed filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 pyyaml-6.0.2 typing-extensions-4.15.0\n"
          ]
        }
      ],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "0159d2754ce54e18b5bc7b5fae2b74c9",
            "53a4c3b15313412dabc18fb32764ee01",
            "e48299e1fb874df08aa55b4a8dbb0f6b",
            "b6c324b2ad0640df9dcfb68e00130e6e",
            "9aaba4bb22b547af9f3d27ef93bc6fc9",
            "17821bc327134378b52e33a916771005",
            "af2103b909884f9fa17d2ca48f9a93c9",
            "e0f894d22e194180b96f567a23e0bb79",
            "81ceea7dca134243be25b1d9ccaee5eb",
            "81d8a23e1b294bd8abf942cc8054847e",
            "fbd91f31d52945b3a3b84bf20955bb57",
            "fe41f079f4a4495c94efc4a066a64133",
            "ddcbf798de7746a4b988d4787f60a5bc",
            "26a72f0ea9964bdf90c360e433ae8e76",
            "519830e41e154c9b9242e9af04daee7e",
            "3fd770c8637b487e8d1fb83366371e6e",
            "92e8dab87f364f889e1d407ef4446c8a",
            "64a05d2acda6460882c4c116d9f1b60e",
            "ab48fc5b75e84c16bffaf5478d1ac239",
            "44d01afae3ff4adb9f4d7fe2e79fbf58"
          ]
        },
        "id": "2_2x9PzU8Mpr",
        "outputId": "079a35b4-f6ab-465b-b7fd-6c244bc360e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0159d2754ce54e18b5bc7b5fae2b74c9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# huggingface login\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "ffa830a536d04f778bb298fbc16563a5",
            "69dde01d92b1450daba1ba80e6a2d6f6",
            "6d6e79604bd74c5b9b25aaa2462ff364",
            "885a535dd15d4cc9af05c66c38cd656c",
            "11a13ebe13704463bd2a82a71c6e133d",
            "b0f3dfbcbc2d4530be1bf036e134377f",
            "525f943b4d654ed08e82ce99d59c9028",
            "1e84f983ee9b4f38ba77947aeab964ed",
            "fb6ceae4cf224494b1c05621ec4f5728",
            "a1deeb094e26418a9857985f22ede5ed",
            "6103a183437146fe9547bf9fba161d24",
            "1b88b4840fbb47d4ab52d3000d826233",
            "67ae1efed70145d78c1586832af2913e",
            "6955e9193e1044c88013d937df1d1574",
            "a2c01653362f409490260992075d27fc",
            "52ad013e5a65455182b024cab2cbb315",
            "2ee4d654e4584875846bab836aacde25",
            "a80a5d1fd4ae4a8ebc5155b9de8ecc77",
            "ec771d987f4c4eb49223c1307aa3a744",
            "6cd503ce0937400385f2636c8643693e",
            "7d6b3911bdef40f7b521243f1422eacf",
            "1f6b97f2565d461ab1dda48907673913",
            "f87a4f413aa043bd848caf301c15470e",
            "53427a589d9c402c8403d02782972085",
            "134583b09e194b86a33118cd55d9af08",
            "8b089b5383a74ad98cb2a51c3d8a3699",
            "2eda7364765d47a799dd7fa2804db1b2",
            "a1717ca8098e4b95bd2ee420d5d5b942",
            "533bf2174fa24bebbff7833bfcd69013",
            "6ad57d9208ac41658b2c0d583deff563",
            "71a3185a24b648a9861ab1ffaa78e67d",
            "d7d4f08dbcd0473e99eede366c9d1beb",
            "160679c207ea434783559dda47ffce04",
            "46064920e943421d805f3406ca5210d5",
            "01780f64e1484790a47ac949805b8058",
            "82e1cd495cc74074886a04db78142f2f",
            "6b9eb23f689d46a7bb006ad12155b10e",
            "d601cfe668c147738706c220cb350164",
            "62b1833b6e554d1d89b4fa39594aeb80",
            "cb40c4be565a4420802cbadd98b4fcb6",
            "c9ec982040b5428f8cc8dac771b2b225",
            "6acb6ad55c424c68b611b0f90fe61037",
            "2dd6ecf4f23b483087886569be549f2c",
            "dd778b7b9fd44dffb93f82112856fa75"
          ]
        },
        "id": "qgjAADBFHB0S",
        "outputId": "94c04f61-5a01-4e3e-82d1-74ad3a424297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffa830a536d04f778bb298fbc16563a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model.v3:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b88b4840fbb47d4ab52d3000d826233"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "params.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f87a4f413aa043bd848caf301c15470e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "consolidated.safetensors:   0%|          | 0.00/14.5G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46064920e943421d805f3406ca5210d5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "\n",
        "mistral_models_path = Path.home().joinpath('mistral_models', '7B-v0.3')\n",
        "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)\n",
        "\n",
        "! cp -r /root/mistral_models/7B-v0.3 /content/mistral_models\n",
        "! rm -r /root/mistral_models/7B-v0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdl_R5baUyha",
        "outputId": "8d919152-467b-4521-b469-8071cf71870c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-25 16:12:04--  https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar\n",
            "Resolving models.mistralcdn.com (models.mistralcdn.com)... 172.67.70.68, 104.26.7.117, 104.26.6.117, ...\n",
            "Connecting to models.mistralcdn.com (models.mistralcdn.com)|172.67.70.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14496675840 (14G) [application/x-tar]\n",
            "Saving to: ‘mistral-7B-v0.3.tar’\n",
            "\n",
            "mistral-7B-v0.3.tar 100%[===================>]  13.50G  41.9MB/s    in 6m 34s  \n",
            "\n",
            "2025-09-25 16:18:38 (35.1 MB/s) - ‘mistral-7B-v0.3.tar’ saved [14496675840/14496675840]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Alternatively, you can download the model from mistral\n",
        "\n",
        "#!wget https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IgJWR-fReilz"
      },
      "outputs": [],
      "source": [
        "#!DIR=/content/mistral_models && mkdir -p $DIR && tar -xf mistral-7B-v0.3.tar -C $DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PxYGmcy4gu0",
        "outputId": "33459ba7-56e9-4c58-a032-8c9819a8e0ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "consolidated.safetensors  params.json  tokenizer.model.v3\n"
          ]
        }
      ],
      "source": [
        "!ls /content/mistral_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ams-19wF8zgY"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "To ensure effective training, mistral-finetune has strict requirements for how the training data has to be formatted. Check out the required data formatting [here](https://github.com/mistralai/mistral-finetune/tree/main?tab=readme-ov-file#prepare-dataset).\n",
        "\n",
        "In this example, let’s use the ultrachat_200k dataset. We load a chunk of the data into Pandas Dataframes, split the data into training and validation, and save the data into the required `jsonl` format for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T33N2SwCIhEl",
        "outputId": "8ea1f8de-8b6f-4ce6-cf2a-48db63629454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i7bmgXvG1vUq"
      },
      "outputs": [],
      "source": [
        "# make a new directory called data\n",
        "!mkdir -p data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br2czKwwFLE8",
        "outputId": "c7047b9f-f65b-417f-ab9b-992439fcc365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ],
      "source": [
        "# navigate to this data directory\n",
        "%cd /content/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download datasets\n",
        "!wget --header=\"Authorization: Bearer $(cat ~/.cache/huggingface/token)\" https://huggingface.co/datasets/baggettersol/ct_train_full/resolve/main/ct-train-split.jsonl\n",
        "!wget --header=\"Authorization: Bearer $(cat ~/.cache/huggingface/token)\" https://huggingface.co/datasets/baggettersol/ct_train_full/resolve/main/ct-eval-split.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHfxMZzKtOX",
        "outputId": "bb7d75a9-de79-4cf7-f034-839142145847"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-25 18:05:36--  https://huggingface.co/datasets/baggettersol/ct_train_full/resolve/main/ct-train-split.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/68d1f59b477c8090d3538a82/1d70b25b94bdb8b2c3d560713c5e1f7b07f78bee102c89ed4d1e9eb529c7bb93?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250925T180536Z&X-Amz-Expires=3600&X-Amz-Signature=ae7c5340339ef3ea0db926be0fbf4629476a1cbdcbc8fbfca4764925799b064e&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=68cb00794f4a18655401a752&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ct-train-split.jsonl%3B+filename%3D%22ct-train-split.jsonl%22%3B&x-id=GetObject&Expires=1758827136&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODgyNzEzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGQxZjU5YjQ3N2M4MDkwZDM1MzhhODIvMWQ3MGIyNWI5NGJkYjhiMmMzZDU2MDcxM2M1ZTFmN2IwN2Y3OGJlZTEwMmM4OWVkNGQxZTllYjUyOWM3YmI5MyoifV19&Signature=jnJvOoGzEdav4hhEmoOR6nnvsdpVv3z7A5YNJ0eKZkA73ncHfEF8FLb-6fMxekUPeIzM7aWk1RbuVT55jeNzoY2FqDI0iXUauH47oiHoMkJgiPNEL7AcdEN7yNy3pMn1k3DOG7%7ERs7Hni4PXJ4FZxz-Vm2wfRoT3fpjsCL3YyBa%7Eqc36z7vcs6R8ohC6%7EwRh8IRnODyjdTfuiTfTbpW2fEtNmyY32dR6QySWe%7E%7E7iKSfVH6mFKKTilvMdXmb5CGWpuNmWHqjF8nNHZT-5-ybLp1QwZUaqcbDMUuInkVZ8dKyzBonVOGZGzG1niJgkqwrroymNsBJd0YA4-LBo8Y8xQ__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-25 18:05:36--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68d1f59b477c8090d3538a82/1d70b25b94bdb8b2c3d560713c5e1f7b07f78bee102c89ed4d1e9eb529c7bb93?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250925T180536Z&X-Amz-Expires=3600&X-Amz-Signature=ae7c5340339ef3ea0db926be0fbf4629476a1cbdcbc8fbfca4764925799b064e&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=68cb00794f4a18655401a752&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ct-train-split.jsonl%3B+filename%3D%22ct-train-split.jsonl%22%3B&x-id=GetObject&Expires=1758827136&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODgyNzEzNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGQxZjU5YjQ3N2M4MDkwZDM1MzhhODIvMWQ3MGIyNWI5NGJkYjhiMmMzZDU2MDcxM2M1ZTFmN2IwN2Y3OGJlZTEwMmM4OWVkNGQxZTllYjUyOWM3YmI5MyoifV19&Signature=jnJvOoGzEdav4hhEmoOR6nnvsdpVv3z7A5YNJ0eKZkA73ncHfEF8FLb-6fMxekUPeIzM7aWk1RbuVT55jeNzoY2FqDI0iXUauH47oiHoMkJgiPNEL7AcdEN7yNy3pMn1k3DOG7%7ERs7Hni4PXJ4FZxz-Vm2wfRoT3fpjsCL3YyBa%7Eqc36z7vcs6R8ohC6%7EwRh8IRnODyjdTfuiTfTbpW2fEtNmyY32dR6QySWe%7E%7E7iKSfVH6mFKKTilvMdXmb5CGWpuNmWHqjF8nNHZT-5-ybLp1QwZUaqcbDMUuInkVZ8dKyzBonVOGZGzG1niJgkqwrroymNsBJd0YA4-LBo8Y8xQ__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.238.243.30, 18.238.243.58, 18.238.243.52, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.238.243.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24394488 (23M)\n",
            "Saving to: ‘ct-train-split.jsonl’\n",
            "\n",
            "ct-train-split.json 100%[===================>]  23.26M   127MB/s    in 0.2s    \n",
            "\n",
            "2025-09-25 18:05:36 (127 MB/s) - ‘ct-train-split.jsonl’ saved [24394488/24394488]\n",
            "\n",
            "--2025-09-25 18:05:36--  https://huggingface.co/datasets/baggettersol/ct_train_full/resolve/main/ct-eval-split.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2710324 (2.6M) [text/plain]\n",
            "Saving to: ‘ct-eval-split.jsonl’\n",
            "\n",
            "ct-eval-split.jsonl 100%[===================>]   2.58M  7.72MB/s    in 0.3s    \n",
            "\n",
            "2025-09-25 18:05:37 (7.72 MB/s) - ‘ct-eval-split.jsonl’ saved [2710324/2710324]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIK0VFXHIn8r",
        "outputId": "379a137d-ac6b-4798-a220-73d78cea25a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mistral-finetune\n"
          ]
        }
      ],
      "source": [
        "# navigate to the mistral-finetune directory\n",
        "%cd /content/mistral-finetune/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hia7n0T1_mHZ"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZtcLerooWFeB"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "# these info is needed for training\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5dxTlIQMaJGv"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "# define training configuration\n",
        "# for your own use cases, you might want to change the data paths, model path, run_dir, and other hyperparameters\n",
        "\n",
        "config = \"\"\"\n",
        "# data\n",
        "data:\n",
        "  instruct_data: \"/content/data/ct-train-split.jsonl\"  # Fill\n",
        "  data: \"\"  # Optionally fill with pretraining data\n",
        "  eval_instruct_data: \"/content/data/ct-eval-split.jsonl\"  # Optionally fill\n",
        "\n",
        "# model\n",
        "model_id_or_path: \"/content/mistral_models\"  # Change to downloaded path\n",
        "lora:\n",
        "  rank: 64\n",
        "  dropout: 0.05\n",
        "\n",
        "# optim\n",
        "# tokens per training steps = batch_size x num_GPUs x seq_len\n",
        "# we recommend sequence length of 32768\n",
        "# If you run into memory error, you can try reduce the sequence length\n",
        "seq_len: 8192\n",
        "batch_size: 1\n",
        "num_microbatches: 8\n",
        "max_steps: 12500\n",
        "optim:\n",
        "  lr: 1.e-4\n",
        "  weight_decay: 0.1\n",
        "  pct_start: 0.05\n",
        "\n",
        "# other\n",
        "seed: 0\n",
        "log_freq: 10\n",
        "eval_freq: 1000\n",
        "no_eval: False\n",
        "ckpt_freq: 2500\n",
        "num_ckpt_keep: 5\n",
        "\n",
        "save_adapters: True  # save only trained LoRA adapters. Set to `False` to merge LoRA adapter into the base model and save full fine-tuned model\n",
        "\n",
        "run_dir: \"/content/test_ultra\"  # Fill\n",
        "\"\"\"\n",
        "\n",
        "# save the same file locally into the example.yaml file\n",
        "import yaml\n",
        "with open('example.yaml', 'w') as file:\n",
        "    yaml.dump(yaml.safe_load(config), file)\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validate data\n",
        "\n",
        "!conda run -n myenv python -m utils.validate_data.py example.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdAAUZNDL6fD",
        "outputId": "fcf9c21e-d389-42fb-b242-afde7dff97e0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/myenv/bin/python: Error while finding module specification for 'utils.validate_data.py' (ModuleNotFoundError: __path__ attribute not found on 'utils.validate_data' while trying to find 'utils.validate_data.py'). Try using 'utils.validate_data' instead of 'utils.validate_data.py' as the module name.\n",
            "\n",
            "ERROR conda.cli.main_run:execute(125): `conda run python -m utils.validate_data.py example.yaml` failed. (See above for error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downgrade numpy\n",
        "%%bash\n",
        "source activate myenv\n",
        "\n",
        "pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXuy_mbgOozs",
        "outputId": "4c961276-d7ae-43bf-a8d4-731bd87911c1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 129.9 MB/s  0:00:00\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "Successfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fix that mistral bs\n",
        "\n",
        "!conda run -n myenv python -m pip install mistral-common==1.3.1 --force-reinstall"
      ],
      "metadata": {
        "id": "WZqfbHfTPQbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5ec694-80ae-448b-c192-73c4ad85d93a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral-common==1.3.1\n",
            "  Downloading mistral_common-1.3.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting jsonschema==4.21.1 (from mistral-common==1.3.1)\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting pydantic==2.6.1 (from mistral-common==1.3.1)\n",
            "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
            "Collecting sentencepiece==0.2.0 (from mistral-common==1.3.1)\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from mistral-common==1.3.1)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-extensions<5.0.0,>=4.11.0 (from mistral-common==1.3.1)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema==4.21.1->mistral-common==1.3.1)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema==4.21.1->mistral-common==1.3.1)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema==4.21.1->mistral-common==1.3.1)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema==4.21.1->mistral-common==1.3.1)\n",
            "  Using cached rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic==2.6.1->mistral-common==1.3.1)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.16.2 (from pydantic==2.6.1->mistral-common==1.3.1)\n",
            "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<0.8.0,>=0.7.0->mistral-common==1.3.1)\n",
            "  Using cached regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests>=2.26.0 (from tiktoken<0.8.0,>=0.7.0->mistral-common==1.3.1)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common==1.3.1)\n",
            "  Using cached charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common==1.3.1)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common==1.3.1)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken<0.8.0,>=0.7.0->mistral-common==1.3.1)\n",
            "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading mistral_common-1.3.1-py3-none-any.whl (3.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 10.3 MB/s  0:00:00\n",
            "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
            "Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 72.1 MB/s  0:00:00\n",
            "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 37.5 MB/s  0:00:00\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 50.1 MB/s  0:00:00\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (152 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Using cached rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "Installing collected packages: sentencepiece, urllib3, typing-extensions, rpds-py, regex, idna, charset_normalizer, certifi, attrs, annotated-types, requests, referencing, pydantic-core, tiktoken, pydantic, jsonschema-specifications, jsonschema, mistral-common\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: rpds-py\n",
            "    Found existing installation: rpds-py 0.27.1\n",
            "    Uninstalling rpds-py-0.27.1:\n",
            "      Successfully uninstalled rpds-py-0.27.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2025.9.18\n",
            "    Uninstalling regex-2025.9.18:\n",
            "      Successfully uninstalled regex-2025.9.18\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.3\n",
            "    Uninstalling charset-normalizer-3.4.3:\n",
            "      Successfully uninstalled charset-normalizer-3.4.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.8.3\n",
            "    Uninstalling certifi-2025.8.3:\n",
            "      Successfully uninstalled certifi-2025.8.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.36.2\n",
            "    Uninstalling referencing-0.36.2:\n",
            "      Successfully uninstalled referencing-0.36.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.11.0\n",
            "    Uninstalling tiktoken-0.11.0:\n",
            "      Successfully uninstalled tiktoken-0.11.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.9\n",
            "    Uninstalling pydantic-2.11.9:\n",
            "      Successfully uninstalled pydantic-2.11.9\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2025.9.1\n",
            "    Uninstalling jsonschema-specifications-2025.9.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2025.9.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.25.1\n",
            "    Uninstalling jsonschema-4.25.1:\n",
            "      Successfully uninstalled jsonschema-4.25.1\n",
            "  Attempting uninstall: mistral-common\n",
            "    Found existing installation: mistral_common 1.8.5\n",
            "    Uninstalling mistral_common-1.8.5:\n",
            "      Successfully uninstalled mistral_common-1.8.5\n",
            "\n",
            "Successfully installed annotated-types-0.7.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 jsonschema-4.21.1 jsonschema-specifications-2025.9.1 mistral-common-1.3.1 pydantic-2.6.1 pydantic-core-2.16.2 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 rpds-py-0.27.1 sentencepiece-0.2.0 tiktoken-0.7.0 typing-extensions-4.15.0 urllib3-2.5.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /usr/local/envs/myenv/etc/conda/activate.d\n",
        "!echo 'export CUDA_VISIBLE_DEVICES=0' > /usr/local/envs/myenv/etc/conda/activate.d/env_vars.sh"
      ],
      "metadata": {
        "id": "9tTniLMGP9KQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ErD1ktQUMyPZ"
      },
      "outputs": [],
      "source": [
        "# make sure the run_dir has not been created before\n",
        "# only run this when you ran torchrun previously and created the /content/test_ultra file\n",
        "!rm -r /content/test_ultra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4wFgmwIUTtg",
        "outputId": "015ab92b-de77-4bc7-e198-4c0221739ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args: TrainArgs(data=DataArgs(data='', shuffle=False, instruct_data='/content/data/ct-train-split.jsonl', eval_instruct_data='/content/data/ct-eval-split.jsonl', instruct=InstructArgs(shuffle=True, dynamic_chunk_fn_call=True)), model_id_or_path='/content/mistral_models', run_dir='/content/test_ultra', optim=OptimArgs(lr=0.0001, weight_decay=0.1, pct_start=0.05), seed=0, num_microbatches=8, seq_len=32768, batch_size=1, max_norm=1.0, max_steps=12500, log_freq=10, ckpt_freq=2500, save_adapters=True, no_ckpt=False, num_ckpt_keep=5, eval_freq=1000, no_eval=False, checkpoint=True, world_size=1, wandb=WandbArgs(project=None, offline=False, key=None, run_name=None), mlflow=MLFlowArgs(tracking_uri=None, experiment_name=None), lora=LoraArgs(enable=True, rank=64, dropout=0.05, scaling=2.0))\n",
            "2025-09-25 18:39:03 (UTC) - 0:00:02 - distributed - INFO - torch.cuda.device_count: 1\n",
            "2025-09-25 18:39:03 (UTC) - 0:00:02 - distributed - INFO - CUDA_VISIBLE_DEVICES: 0\n",
            "2025-09-25 18:39:03 (UTC) - 0:00:02 - distributed - INFO - local rank: 0\n",
            "2025-09-25 18:39:03 (UTC) - 0:00:02 - train - INFO - Going to init comms...\n",
            "2025-09-25 18:39:03 (UTC) - 0:00:02 - train - INFO - Run dir: /content/test_ultra\n",
            "2025-09-25 18:39:03 (UTC) - 0:00:03 - train - INFO - TrainArgs: {'batch_size': 1,\n",
            " 'checkpoint': True,\n",
            " 'ckpt_freq': 2500,\n",
            " 'data': {'data': '',\n",
            "          'eval_instruct_data': '/content/data/ct-eval-split.jsonl',\n",
            "          'instruct': {'dynamic_chunk_fn_call': True, 'shuffle': True},\n",
            "          'instruct_data': '/content/data/ct-train-split.jsonl',\n",
            "          'shuffle': False},\n",
            " 'eval_freq': 1000,\n",
            " 'log_freq': 10,\n",
            " 'lora': {'dropout': 0.05, 'enable': True, 'rank': 64, 'scaling': 2.0},\n",
            " 'max_norm': 1.0,\n",
            " 'max_steps': 12500,\n",
            " 'mlflow': {'experiment_name': None, 'tracking_uri': None},\n",
            " 'model_id_or_path': '/content/mistral_models',\n",
            " 'no_ckpt': False,\n",
            " 'no_eval': False,\n",
            " 'num_ckpt_keep': 5,\n",
            " 'num_microbatches': 8,\n",
            " 'optim': {'lr': 0.0001, 'pct_start': 0.05, 'weight_decay': 0.1},\n",
            " 'run_dir': '/content/test_ultra',\n",
            " 'save_adapters': True,\n",
            " 'seed': 0,\n",
            " 'seq_len': 32768,\n",
            " 'wandb': {'key': None, 'offline': False, 'project': None, 'run_name': None},\n",
            " 'world_size': 1}\n",
            "2025-09-25 18:39:05 (UTC) - 0:00:05 - finetune.wrapped_model - INFO - Reloading model from /content/mistral_models/consolidated.safetensors ...\n",
            "2025-09-25 18:39:05 (UTC) - 0:00:05 - finetune.wrapped_model - INFO - Converting model to dtype torch.bfloat16 ...\n",
            "2025-09-25 18:39:06 (UTC) - 0:00:05 - finetune.wrapped_model - INFO - Loaded model on cpu!\n",
            "2025-09-25 18:39:06 (UTC) - 0:00:05 - finetune.wrapped_model - INFO - Initializing lora layers ...\n",
            "2025-09-25 18:39:07 (UTC) - 0:00:06 - finetune.wrapped_model - INFO - Finished initialization!\n",
            "2025-09-25 18:39:07 (UTC) - 0:00:06 - finetune.wrapped_model - INFO - Sharding model over 1 GPUs ...\n",
            "2025-09-25 18:39:11 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - Model sharded!\n",
            "2025-09-25 18:39:11 (UTC) - 0:00:11 - finetune.wrapped_model - INFO - 167,772,160 out of 7,415,795,712 parameters are finetuned (2.26%).\n",
            "2025-09-25 18:39:12 (UTC) - 0:00:11 - dataset - INFO - Loading /content/data/ct-train-split.jsonl ...\n",
            "2025-09-25 18:39:36 (UTC) - 0:00:35 - dataset - INFO - /content/data/ct-train-split.jsonl loaded and tokenized.\n",
            "2025-09-25 18:39:36 (UTC) - 0:00:35 - dataset - INFO - Shuffling /content/data/ct-train-split.jsonl ...\n",
            "[2025-09-25 18:42:56,120] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
            "\n",
            "CondaError: KeyboardInterrupt\n",
            "[2025-09-25 18:42:56,120] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 33896 closing signal SIGINT\n",
            "\n",
            "2025-09-25 18:42:58 (UTC) - 0:03:57 - utils - INFO - Closing: eval_logger\n",
            "2025-09-25 18:42:58 (UTC) - 0:03:57 - utils - INFO - Closed: eval_logger\n",
            "2025-09-25 18:42:58 (UTC) - 0:03:57 - utils - INFO - Closing: metrics_logger\n",
            "2025-09-25 18:42:58 (UTC) - 0:03:57 - utils - INFO - Closed: metrics_logger\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/mistral-finetune/train.py\", line 328, in <module>\n",
            "    fire.Fire(train)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/content/mistral-finetune/train.py\", line 65, in train\n",
            "    _train(args, exit_stack)\n",
            "  File \"/content/mistral-finetune/train.py\", line 250, in _train\n",
            "    mb_loss.backward()\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/_tensor.py\", line 522, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/myenv/bin/torchrun\", line 7, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/run.py\", line 812, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/run.py\", line 803, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 135, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 259, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py\", line 123, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 727, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py\", line 868, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 33879 got signal: 2\n"
          ]
        }
      ],
      "source": [
        "# start training\n",
        "!conda run --live-stream -n myenv torchrun --nproc-per-node 1 -m train example.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruJ29JFn98zE"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7BWNGKt9-Kxz",
        "outputId": "f9730b9e-71f2-4c53-d800-62c7ebd12887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral_inference\n",
            "  Downloading mistral_inference-1.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting fire>=0.6.0 (from mistral_inference)\n",
            "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_inference)\n",
            "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral_inference)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting safetensors>=0.4.0 (from mistral_inference)\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting simple-parsing>=0.1.5 (from mistral_inference)\n",
            "  Using cached simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting xformers>=0.0.24 (from mistral_inference)\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting termcolor (from fire>=0.6.0->mistral_inference)\n",
            "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pydantic<3.0,>=2.7 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.11.0 in /usr/local/lib/python3.11/site-packages (from mistral_common>=1.5.4->mistral_inference) (4.15.0)\n",
            "Collecting tiktoken>=0.7.0 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from mistral_common>=1.5.4->mistral_inference) (2.32.3)\n",
            "Collecting numpy>=1.25 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing>=0.1.5->mistral_inference)\n",
            "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting torch==2.8.0 (from xformers>=0.0.24->mistral_inference)\n",
            "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch==2.8.0->xformers>=0.0.24->mistral_inference) (3.19.1)\n",
            "Collecting sympy>=1.13.3 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch==2.8.0->xformers>=0.0.24->mistral_inference) (2025.9.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0->xformers>=0.0.24->mistral_inference) (65.6.3)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2024.12.14)\n",
            "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading mistral_inference-1.6.0-py3-none-any.whl (32 kB)\n",
            "Using cached fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Using cached mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m140.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Using cached simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m126.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Downloading numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m172.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-inspection, triton, termcolor, sympy, safetensors, rpds-py, regex, pydantic-core, pycountry, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, docstring-parser, attrs, annotated-types, tiktoken, simple-parsing, referencing, pydantic, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, fire, pydantic-extra-types, nvidia-cusolver-cu12, jsonschema-specifications, torch, jsonschema, xformers, mistral_common, mistral_inference\n",
            "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 attrs-25.3.0 docstring-parser-0.17.0 fire-0.7.1 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 mistral_common-1.8.5 mistral_inference-1.6.0 mpmath-1.3.0 networkx-3.5 numpy-2.3.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pillow-11.3.0 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 referencing-0.36.2 regex-2025.9.18 rpds-py-0.27.1 safetensors-0.6.2 simple-parsing-0.1.7 sympy-1.14.0 termcolor-3.1.0 tiktoken-0.11.0 torch-2.8.0 triton-3.4.0 typing-inspection-0.4.1 xformers-0.0.32.post2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "0e342a16503841359bdb97b128acd821"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install mistral_inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/test_ultra.zip /content/test_ultra"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCTm11hg8DF5",
        "outputId": "ecb55fec-26ed-41d7-942f-ee2c9121e793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/test_ultra/ (stored 0%)\n",
            "  adding: content/test_ultra/args.yaml (deflated 47%)\n",
            "  adding: content/test_ultra/checkpoints/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/tokenizer.model.v3 (deflated 61%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/params.json (deflated 49%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/lora.safetensors (deflated 21%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000100/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000100/consolidated/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000100/consolidated/tokenizer.model.v3 (deflated 61%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000100/consolidated/params.json (deflated 49%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000100/consolidated/lora.safetensors (deflated 21%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000400/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000400/consolidated/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000400/consolidated/tokenizer.model.v3 (deflated 61%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000400/consolidated/params.json (deflated 49%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000400/consolidated/lora.safetensors (deflated 21%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000300/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000300/consolidated/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000300/consolidated/tokenizer.model.v3 (deflated 61%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000300/consolidated/params.json (deflated 49%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000300/consolidated/lora.safetensors (deflated 21%)\n",
            "  adding: content/test_ultra/metrics.train.jsonl (deflated 76%)\n",
            "  adding: content/test_ultra/tb/ (stored 0%)\n",
            "  adding: content/test_ultra/tb/events.out.tfevents.1758618942.c3ae9aa944e8.38330.1.eval (deflated 9%)\n",
            "  adding: content/test_ultra/tb/events.out.tfevents.1758618942.c3ae9aa944e8.38330.0.train (deflated 73%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n myenv python -m pip install mistral_inference"
      ],
      "metadata": {
        "id": "q6UxM45_fnbR",
        "outputId": "c7cba961-683f-4bfc-b33e-77a6f80db62f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral_inference\n",
            "  Using cached mistral_inference-1.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: fire>=0.6.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_inference) (0.7.1)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_inference)\n",
            "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_inference) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_inference) (0.6.2)\n",
            "Requirement already satisfied: simple-parsing>=0.1.5 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_inference) (0.1.7)\n",
            "Requirement already satisfied: xformers>=0.0.24 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_inference) (0.0.24)\n",
            "Requirement already satisfied: termcolor in /usr/local/envs/myenv/lib/python3.10/site-packages (from fire>=0.6.0->mistral_inference) (3.1.0)\n",
            "Collecting pydantic<3.0,>=2.7 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_common>=1.5.4->mistral_inference) (4.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.11.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_common>=1.5.4->mistral_inference) (4.15.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_common>=1.5.4->mistral_inference) (0.7.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_common>=1.5.4->mistral_inference) (2.32.5)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/envs/myenv/lib/python3.10/site-packages (from mistral_common>=1.5.4->mistral_inference) (1.26.4)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/envs/myenv/lib/python3.10/site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference) (2.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference) (0.7.0)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference) (0.4.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/envs/myenv/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/envs/myenv/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/envs/myenv/lib/python3.10/site-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (0.27.1)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/envs/myenv/lib/python3.10/site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference) (24.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/envs/myenv/lib/python3.10/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/myenv/lib/python3.10/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/myenv/lib/python3.10/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/myenv/lib/python3.10/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2025.8.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/envs/myenv/lib/python3.10/site-packages (from simple-parsing>=0.1.5->mistral_inference) (0.17.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/envs/myenv/lib/python3.10/site-packages (from tiktoken>=0.7.0->mistral_common>=1.5.4->mistral_inference) (2025.9.18)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from xformers>=0.0.24->mistral_inference) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.19.1)\n",
            "Requirement already satisfied: sympy in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2025.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from torch==2.2.0->xformers>=0.0.24->mistral_inference) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/envs/myenv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->xformers>=0.0.24->mistral_inference) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from jinja2->torch==2.2.0->xformers>=0.0.24->mistral_inference) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from sympy->torch==2.2.0->xformers>=0.0.24->mistral_inference) (1.3.0)\n",
            "Using cached mistral_inference-1.6.0-py3-none-any.whl (32 kB)\n",
            "Using cached mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Installing collected packages: pydantic-core, pydantic, mistral_common, mistral_inference\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.16.2\n",
            "    Uninstalling pydantic_core-2.16.2:\n",
            "      Successfully uninstalled pydantic_core-2.16.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "  Attempting uninstall: mistral_common\n",
            "    Found existing installation: mistral_common 1.3.1\n",
            "    Uninstalling mistral_common-1.3.1:\n",
            "      Successfully uninstalled mistral_common-1.3.1\n",
            "\n",
            "Successfully installed mistral_common-1.8.5 mistral_inference-1.6.0 pydantic-2.11.9 pydantic-core-2.33.2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-xLs2Ot9-il",
        "outputId": "1143632c-ebaa-4040-a21f-b454ed53270d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I’m not a rugger\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/envs/myenv/lib/python3.10/site-packages/mistral_common/tokens/tokenizers/sentencepiece.py:175: FutureWarning: Using the tokenizer's special token policy `None` is deprecated. It will be removed in 1.10.0. Please pass a special token policy explicitly. Future default will be SpecialTokenPolicy.IGNORE.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "from mistral_inference.transformer import Transformer\n",
        "from mistral_inference.generate import generate\n",
        "\n",
        "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
        "from mistral_common.protocol.instruct.messages import UserMessage\n",
        "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
        "\n",
        "\n",
        "tokenizer = MistralTokenizer.from_file(\"/content/mistral_models/tokenizer.model.v3\")  # change to extracted tokenizer file\n",
        "model = Transformer.from_folder(\"/content/mistral_models\")  # change to extracted model dir\n",
        "model.load_lora(\"/content/test_ultra/checkpoints/checkpoint_000100/consolidated/lora.safetensors\")\n",
        "\n",
        "completion_request = ChatCompletionRequest(messages=[UserMessage(content=\"bruh this coin is a rug\")])\n",
        "\n",
        "tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
        "\n",
        "out_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
        "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
        "\n",
        "print(result)\n",
        "EOF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Checkpoints"
      ],
      "metadata": {
        "id": "K_6zAxQQhUoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#optional if you are uploading file\n",
        "\n",
        "#!unzip /content/test_ultra.zip -d /content/\n",
        "#!mv /content/content/* /content/\n",
        "#!rm -rf /content/content/"
      ],
      "metadata": {
        "id": "sTy9Si6SklHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make merged directory for saving merged model\n",
        "\n",
        "!mkdir -p /content/merged"
      ],
      "metadata": {
        "id": "1jdKOgnosS3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge checkpoints\n",
        "\n",
        "!conda run --live-stream -n myenv python3 /content/mistral-finetune/utils/merge_lora.py --initial_model_ckpt /content/mistral_models/consolidated.safetensors --lora_ckpt /content/test_ultra/checkpoints/checkpoint_000400/consolidated/lora.safetensors --dump_ckpt /content/merged/consolidated.safetensors --scaling 2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIzAlXP8hZzR",
        "outputId": "a1d6f7ec-2cbf-4585-b80e-649bf8f36142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging to torch.bfloat16 precision...\n",
            "100% 224/224 [00:13<00:00, 16.63it/s]\n",
            "100% 291/291 [00:00<00:00, 755286.18it/s]\n",
            "Merged checkpoint saved to /content/merged/consolidated.safetensors\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0159d2754ce54e18b5bc7b5fae2b74c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_af2103b909884f9fa17d2ca48f9a93c9"
          }
        },
        "53a4c3b15313412dabc18fb32764ee01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f894d22e194180b96f567a23e0bb79",
            "placeholder": "​",
            "style": "IPY_MODEL_81ceea7dca134243be25b1d9ccaee5eb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e48299e1fb874df08aa55b4a8dbb0f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_81d8a23e1b294bd8abf942cc8054847e",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd91f31d52945b3a3b84bf20955bb57",
            "value": ""
          }
        },
        "b6c324b2ad0640df9dcfb68e00130e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_fe41f079f4a4495c94efc4a066a64133",
            "style": "IPY_MODEL_ddcbf798de7746a4b988d4787f60a5bc",
            "value": true
          }
        },
        "9aaba4bb22b547af9f3d27ef93bc6fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_26a72f0ea9964bdf90c360e433ae8e76",
            "style": "IPY_MODEL_519830e41e154c9b9242e9af04daee7e",
            "tooltip": ""
          }
        },
        "17821bc327134378b52e33a916771005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd770c8637b487e8d1fb83366371e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_92e8dab87f364f889e1d407ef4446c8a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "af2103b909884f9fa17d2ca48f9a93c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e0f894d22e194180b96f567a23e0bb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ceea7dca134243be25b1d9ccaee5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81d8a23e1b294bd8abf942cc8054847e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd91f31d52945b3a3b84bf20955bb57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe41f079f4a4495c94efc4a066a64133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddcbf798de7746a4b988d4787f60a5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26a72f0ea9964bdf90c360e433ae8e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519830e41e154c9b9242e9af04daee7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3fd770c8637b487e8d1fb83366371e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e8dab87f364f889e1d407ef4446c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64a05d2acda6460882c4c116d9f1b60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab48fc5b75e84c16bffaf5478d1ac239",
            "placeholder": "​",
            "style": "IPY_MODEL_44d01afae3ff4adb9f4d7fe2e79fbf58",
            "value": "Connecting..."
          }
        },
        "ab48fc5b75e84c16bffaf5478d1ac239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d01afae3ff4adb9f4d7fe2e79fbf58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffa830a536d04f778bb298fbc16563a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69dde01d92b1450daba1ba80e6a2d6f6",
              "IPY_MODEL_6d6e79604bd74c5b9b25aaa2462ff364",
              "IPY_MODEL_885a535dd15d4cc9af05c66c38cd656c"
            ],
            "layout": "IPY_MODEL_11a13ebe13704463bd2a82a71c6e133d"
          }
        },
        "69dde01d92b1450daba1ba80e6a2d6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f3dfbcbc2d4530be1bf036e134377f",
            "placeholder": "​",
            "style": "IPY_MODEL_525f943b4d654ed08e82ce99d59c9028",
            "value": "Fetching 3 files: 100%"
          }
        },
        "6d6e79604bd74c5b9b25aaa2462ff364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e84f983ee9b4f38ba77947aeab964ed",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb6ceae4cf224494b1c05621ec4f5728",
            "value": 3
          }
        },
        "885a535dd15d4cc9af05c66c38cd656c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1deeb094e26418a9857985f22ede5ed",
            "placeholder": "​",
            "style": "IPY_MODEL_6103a183437146fe9547bf9fba161d24",
            "value": " 3/3 [01:17&lt;00:00, 77.58s/it]"
          }
        },
        "11a13ebe13704463bd2a82a71c6e133d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f3dfbcbc2d4530be1bf036e134377f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525f943b4d654ed08e82ce99d59c9028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e84f983ee9b4f38ba77947aeab964ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb6ceae4cf224494b1c05621ec4f5728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1deeb094e26418a9857985f22ede5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6103a183437146fe9547bf9fba161d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b88b4840fbb47d4ab52d3000d826233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67ae1efed70145d78c1586832af2913e",
              "IPY_MODEL_6955e9193e1044c88013d937df1d1574",
              "IPY_MODEL_a2c01653362f409490260992075d27fc"
            ],
            "layout": "IPY_MODEL_52ad013e5a65455182b024cab2cbb315"
          }
        },
        "67ae1efed70145d78c1586832af2913e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee4d654e4584875846bab836aacde25",
            "placeholder": "​",
            "style": "IPY_MODEL_a80a5d1fd4ae4a8ebc5155b9de8ecc77",
            "value": "tokenizer.model.v3: 100%"
          }
        },
        "6955e9193e1044c88013d937df1d1574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec771d987f4c4eb49223c1307aa3a744",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cd503ce0937400385f2636c8643693e",
            "value": 587404
          }
        },
        "a2c01653362f409490260992075d27fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d6b3911bdef40f7b521243f1422eacf",
            "placeholder": "​",
            "style": "IPY_MODEL_1f6b97f2565d461ab1dda48907673913",
            "value": " 587k/587k [00:00&lt;00:00, 3.58MB/s]"
          }
        },
        "52ad013e5a65455182b024cab2cbb315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee4d654e4584875846bab836aacde25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80a5d1fd4ae4a8ebc5155b9de8ecc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec771d987f4c4eb49223c1307aa3a744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd503ce0937400385f2636c8643693e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d6b3911bdef40f7b521243f1422eacf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f6b97f2565d461ab1dda48907673913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f87a4f413aa043bd848caf301c15470e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53427a589d9c402c8403d02782972085",
              "IPY_MODEL_134583b09e194b86a33118cd55d9af08",
              "IPY_MODEL_8b089b5383a74ad98cb2a51c3d8a3699"
            ],
            "layout": "IPY_MODEL_2eda7364765d47a799dd7fa2804db1b2"
          }
        },
        "53427a589d9c402c8403d02782972085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1717ca8098e4b95bd2ee420d5d5b942",
            "placeholder": "​",
            "style": "IPY_MODEL_533bf2174fa24bebbff7833bfcd69013",
            "value": "params.json: 100%"
          }
        },
        "134583b09e194b86a33118cd55d9af08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ad57d9208ac41658b2c0d583deff563",
            "max": 202,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71a3185a24b648a9861ab1ffaa78e67d",
            "value": 202
          }
        },
        "8b089b5383a74ad98cb2a51c3d8a3699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d4f08dbcd0473e99eede366c9d1beb",
            "placeholder": "​",
            "style": "IPY_MODEL_160679c207ea434783559dda47ffce04",
            "value": " 202/202 [00:00&lt;00:00, 25.9kB/s]"
          }
        },
        "2eda7364765d47a799dd7fa2804db1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1717ca8098e4b95bd2ee420d5d5b942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533bf2174fa24bebbff7833bfcd69013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ad57d9208ac41658b2c0d583deff563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a3185a24b648a9861ab1ffaa78e67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7d4f08dbcd0473e99eede366c9d1beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160679c207ea434783559dda47ffce04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46064920e943421d805f3406ca5210d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01780f64e1484790a47ac949805b8058",
              "IPY_MODEL_82e1cd495cc74074886a04db78142f2f",
              "IPY_MODEL_6b9eb23f689d46a7bb006ad12155b10e"
            ],
            "layout": "IPY_MODEL_d601cfe668c147738706c220cb350164"
          }
        },
        "01780f64e1484790a47ac949805b8058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b1833b6e554d1d89b4fa39594aeb80",
            "placeholder": "​",
            "style": "IPY_MODEL_cb40c4be565a4420802cbadd98b4fcb6",
            "value": "consolidated.safetensors: 100%"
          }
        },
        "82e1cd495cc74074886a04db78142f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ec982040b5428f8cc8dac771b2b225",
            "max": 14496078512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6acb6ad55c424c68b611b0f90fe61037",
            "value": 14496078512
          }
        },
        "6b9eb23f689d46a7bb006ad12155b10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd6ecf4f23b483087886569be549f2c",
            "placeholder": "​",
            "style": "IPY_MODEL_dd778b7b9fd44dffb93f82112856fa75",
            "value": " 14.5G/14.5G [01:17&lt;00:00, 362MB/s]"
          }
        },
        "d601cfe668c147738706c220cb350164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b1833b6e554d1d89b4fa39594aeb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb40c4be565a4420802cbadd98b4fcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ec982040b5428f8cc8dac771b2b225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6acb6ad55c424c68b611b0f90fe61037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dd6ecf4f23b483087886569be549f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd778b7b9fd44dffb93f82112856fa75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}