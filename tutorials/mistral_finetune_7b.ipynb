{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quagmaire/mistral-finetune-2025/blob/main/tutorials/mistral_finetune_7b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyuOCYM92LJb"
      },
      "source": [
        "# Getting Started with Fine-Tuning Mistral 7B\n",
        "\n",
        "This notebook shows you a simple example of how to LoRA finetune Mistral 7B. You can run this notebook in Google Colab with Pro + account with A100 and 40GB RAM.\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mistralai/mistral-finetune/blob/main/tutorials/mistral_finetune_7b.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "\n",
        "Check out `mistral-finetune` Github repo to learn more: https://github.com/mistralai/mistral-finetune/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpyPeNYr8TLk",
        "outputId": "8847e892-20fb-4e0c-ce0b-f11ab83d96fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create --name myenv python=3.10"
      ],
      "metadata": {
        "id": "qSb131CE8V8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5341ded0-7bbb-4b32-f7ad-f5e17554f412"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    bzip2-1.0.8                |       hda65f42_8         254 KB  conda-forge\n",
            "    ca-certificates-2025.8.3   |       hbd8a1cb_0         151 KB  conda-forge\n",
            "    ld_impl_linux-64-2.44      |       h1423503_1         660 KB  conda-forge\n",
            "    libexpat-2.7.1             |       hecca717_0          73 KB  conda-forge\n",
            "    libffi-3.4.6               |       h2dba641_1          56 KB  conda-forge\n",
            "    libgcc-15.1.0              |       h767d61c_5         805 KB  conda-forge\n",
            "    libgcc-ng-15.1.0           |       h69a702a_5          29 KB  conda-forge\n",
            "    libgomp-15.1.0             |       h767d61c_5         437 KB  conda-forge\n",
            "    liblzma-5.8.1              |       hb9d3cd8_2         110 KB  conda-forge\n",
            "    libnsl-2.0.1               |       hb9d3cd8_1          33 KB  conda-forge\n",
            "    libsqlite-3.50.4           |       h0c1763c_0         911 KB  conda-forge\n",
            "    libuuid-2.41.1             |       he9a06e4_0          36 KB  conda-forge\n",
            "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
            "    openssl-3.5.3              |       h26f9b46_0         3.0 MB  conda-forge\n",
            "    pip-25.2                   |     pyh8b19718_0         1.1 MB  conda-forge\n",
            "    python-3.10.18             |hd6af730_0_cpython        23.9 MB  conda-forge\n",
            "    readline-8.2               |       h8c095d6_2         276 KB  conda-forge\n",
            "    setuptools-80.9.0          |     pyhff2d567_0         731 KB  conda-forge\n",
            "    tk-8.6.13                  |noxft_hd72426e_102         3.1 MB  conda-forge\n",
            "    tzdata-2025b               |       h78e105d_0         120 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        36.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hda65f42_8 \n",
            "  ca-certificates    conda-forge/noarch::ca-certificates-2025.8.3-hbd8a1cb_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.44-h1423503_1 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.7.1-hecca717_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1 \n",
            "  libgcc             conda-forge/linux-64::libgcc-15.1.0-h767d61c_5 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.1.0-h69a702a_5 \n",
            "  libgomp            conda-forge/linux-64::libgomp-15.1.0-h767d61c_5 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_2 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hb9d3cd8_1 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.50.4-h0c1763c_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.41.1-he9a06e4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.5.3-h26f9b46_0 \n",
            "  pip                conda-forge/noarch::pip-25.2-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.18-hd6af730_0_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
            "  setuptools         conda-forge/noarch::setuptools-80.9.0-pyhff2d567_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_hd72426e_102 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.18       | 23.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 660 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.1       | 36 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :   0% 0.0006542580201315321/1 [00:00<03:05, 185.87s/it]\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0.004987209317899284/1 [00:00<00:26, 26.35s/it]\u001b[A\n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | :   1% 0.013918149321082462/1 [00:00<00:10, 10.39s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | : 100% 1.0/1 [00:00<00:00,  6.15s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | :   1% 0.005223567010164658/1 [00:00<00:31, 32.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.4     | 911 KB    | : 100% 1.0/1 [00:00<00:00,  6.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  26% 0.2610489500324813/1 [00:00<00:00,  1.41it/s]    \n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.19it/s]                 \u001b[A\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.19it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   2% 0.018375108367605347/1 [00:00<00:12, 12.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:00<00:00, 12.63s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | :   2% 0.019878887296755243/1 [00:00<00:12, 13.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  53% 0.5286404802662779/1 [00:00<00:00,  1.96it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | : 100% 1.0/1 [00:00<00:00, 13.23s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:00<00:00, 13.05s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.53it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 660 KB    | :   2% 0.02423510895740514/1 [00:00<00:14, 15.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | :   4% 0.03663562268707445/1 [00:00<00:10, 10.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   6% 0.05800056641178136/1 [00:00<00:06,  6.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | :   6% 0.06293284576766625/1 [00:00<00:06,  6.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  73% 0.7347317566077105/1 [00:00<00:00,  2.00it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:00<00:00,  6.80s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | : 100% 1.0/1 [00:00<00:00, 10.49s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:00<00:00,  6.45s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :  15% 0.1451272875440679/1 [00:00<00:02,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:00<00:00,  3.45s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | :  11% 0.10611261512156578/1 [00:00<00:04,  4.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | :  22% 0.2190052265041237/1 [00:00<00:01,  2.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | : 100% 1.0/1 [00:00<00:00,  2.33s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | : 100% 1.0/1 [00:00<00:00,  4.79s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :  13% 0.1332379155552664/1 [00:00<00:03,  4.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | :  94% 0.9401687749290115/1 [00:00<00:00,  1.71it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.1       | 36 KB     | :  44% 0.4417720495052175/1 [00:00<00:00,  1.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.1       | 36 KB     | : 100% 1.0/1 [00:00<00:00,  1.31s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | :  49% 0.4857252972043521/1 [00:00<00:00,  1.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :  29% 0.2852715337871955/1 [00:00<00:01,  2.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:00<00:00,  1.23s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:00<00:00,  2.10s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.19it/s]\u001b[A\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | : 100% 1.0/1 [00:01<00:00,  1.71it/s]               \n",
            "\n",
            "\n",
            "pip-25.2             | 1.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.00it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | : 100% 1.0/1 [00:01<00:00,  1.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 805 KB    | : 100% 1.0/1 [00:01<00:00,  1.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.3        | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  3.53it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 660 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 660 KB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:01<00:00,  1.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:01<00:00,  1.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | : 100% 1.0/1 [00:01<00:00,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 437 KB    | : 100% 1.0/1 [00:01<00:00,  1.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:01<00:00,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:01<00:00,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:01<00:00,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:01<00:00,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | : 100% 1.0/1 [00:01<00:00,  1.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libexpat-2.7.1       | 73 KB     | : 100% 1.0/1 [00:01<00:00,  1.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | : 100% 1.0/1 [00:01<00:00,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 151 KB    | : 100% 1.0/1 [00:01<00:00,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.1       | 36 KB     | : 100% 1.0/1 [00:01<00:00,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuuid-2.41.1       | 36 KB     | : 100% 1.0/1 [00:01<00:00,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:01<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libnsl-2.0.1         | 33 KB     | : 100% 1.0/1 [00:01<00:00,  1.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:01<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:01<00:00,  1.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:02<00:00,  2.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:02<00:00,  2.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:02<00:00,  2.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.18       | 23.9 MB   | : 100% 1.0/1 [00:02<00:00,  1.71it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "import sys\n",
        "print(sys.version)\n",
        "EOF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd5S9ctcCOFJ",
        "outputId": "e82a62be-0d75-40c4-849b-60373678e7a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxr8mv-17GfB"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Clone the `mistral-finetune` repo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIj3IlIeVDIb",
        "outputId": "4d18cd55-33f1-4ca0-db89-b25baaa1e905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'mistral-finetune'...\n",
            "remote: Enumerating objects: 472, done.\u001b[K\n",
            "remote: Counting objects: 100% (249/249), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 472 (delta 211), reused 159 (delta 159), pack-reused 223 (from 2)\u001b[K\n",
            "Receiving objects: 100% (472/472), 243.32 KiB | 6.95 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/mistralai/mistral-finetune.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQPd_pGT7WiY"
      },
      "source": [
        "Install all required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuTOGipl7BS7",
        "outputId": "f4518d1a-d9e0-471f-f1e1-13ab905d4900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire (from -r /content/mistral-finetune/requirements.txt (line 1))\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting simple-parsing (from -r /content/mistral-finetune/requirements.txt (line 2))\n",
            "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pyyaml (from -r /content/mistral-finetune/requirements.txt (line 3))\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting mistral-common>=1.3.1 (from -r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting safetensors (from -r /content/mistral-finetune/requirements.txt (line 5))\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting tensorboard (from -r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tqdm (from -r /content/mistral-finetune/requirements.txt (line 7))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting torch==2.2 (from -r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting triton==2.2 (from -r /content/mistral-finetune/requirements.txt (line 10))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting xformers==0.0.24 (from -r /content/mistral-finetune/requirements.txt (line 11))\n",
            "  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting filelock (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting numpy (from xformers==0.0.24->-r /content/mistral-finetune/requirements.txt (line 11))\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting termcolor (from fire->-r /content/mistral-finetune/requirements.txt (line 1))\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing->-r /content/mistral-finetune/requirements.txt (line 2))\n",
            "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pydantic<3.0,>=2.7 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting tiktoken>=0.7.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting requests>=2.0.0 (from mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=2.7->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0,>=2.7->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0,>=2.7->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading grpcio-1.75.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting packaging (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/myenv/lib/python3.10/site-packages (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6)) (80.9.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.0.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->mistral-common>=1.3.1->-r /content/mistral-finetune/requirements.txt (line 4))\n",
            "  Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard->-r /content/mistral-finetune/requirements.txt (line 6))\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.2->-r /content/mistral-finetune/requirements.txt (line 9))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading grpcio-1.75.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
            "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "Downloading pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (152 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Downloading rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.9/789.9 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, termcolor, tensorboard-data-server, sympy, safetensors, rpds-py, regex, pyyaml, pycountry, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, markdown, idna, fsspec, filelock, docstring-parser, charset_normalizer, certifi, attrs, annotated-types, absl-py, werkzeug, typing-inspection, triton, simple-parsing, requests, referencing, pydantic-core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, grpcio, fire, tiktoken, tensorboard, pydantic, nvidia-cusolver-cu12, jsonschema-specifications, torch, pydantic-extra-types, jsonschema, xformers, mistral-common\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59/59\u001b[0m [mistral-common]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 absl-py-2.3.1 annotated-types-0.7.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 docstring-parser-0.17.0 filelock-3.19.1 fire-0.7.1 fsspec-2025.9.0 grpcio-1.75.0 idna-3.10 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 markdown-3.9 mistral-common-1.8.5 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 packaging-25.0 pillow-11.3.0 protobuf-6.32.1 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 pyyaml-6.0.2 referencing-0.36.2 regex-2025.9.18 requests-2.32.5 rpds-py-0.27.1 safetensors-0.6.2 simple-parsing-0.1.7 sympy-1.14.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 termcolor-3.1.0 tiktoken-0.11.0 torch-2.2.0 tqdm-4.67.1 triton-2.2.0 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0 werkzeug-3.1.3 xformers-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!conda run --live-stream -n myenv python -m pip install -r /content/mistral-finetune/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgdIAi257jLo"
      },
      "source": [
        "## Model download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30fa1zgi8Mpr",
        "outputId": "2405d5a9-7032-4dc0-bd86-f070e9ccde26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filelock (from huggingface_hub)\n",
            "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
            "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
            "Collecting pyyaml>=5.1 (from huggingface_hub)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (4.67.1)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)\n",
            "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Downloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: typing-extensions, pyyaml, hf-xet, fsspec, filelock, huggingface_hub\n",
            "Successfully installed filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.0 pyyaml-6.0.2 typing-extensions-4.15.0\n"
          ]
        }
      ],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "8ccf8776754f4937b8a4230bc8325fa4",
            "14bc19491d7d4fcb9f2c3bc95944dd7c",
            "482c5d4b7e824780909d85c5ecf616a2",
            "abc61d5f8ea44549b2daa50268140fe0",
            "9fb91b3e1c8f463db6bb8c548ce81aeb",
            "bcf48d297262447c9cd7126ee8f3816e",
            "ed38a985a29449e68a201616d033ebbe",
            "7d0aa48ea3114a6f9aad34452438182c",
            "de210456e2704f108ff3ddc47838d703",
            "331642fa2e07496688817d161d8aa31d",
            "f7461f869ce443e0a2266c57afdbc5e2",
            "f205dd0ec7b94514ba52c1838971a365",
            "e7bae007a6294259b929a006856bd25b",
            "094fc700d0994f02a307ea38b2e1925b",
            "962dccf4f4e742edb6ce0fb9b69bd4d0",
            "5379d02eba1a42509f5f0b7b575ae74f",
            "946108e7328944a8990de29a309904b8",
            "0d6170202c6449c68344d158ba39a46a",
            "8aa9e9ce6be94866a2df009454284fc4",
            "8a70b545019741c4b609bb2549b166f6"
          ]
        },
        "id": "2_2x9PzU8Mpr",
        "outputId": "3b0e7891-ab17-469c-dde1-1f719450e523"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ccf8776754f4937b8a4230bc8325fa4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# huggingface login\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "4cbdd13e42eb4b24901b34daa35579d2",
            "d939c98fd35341feaf9b54f338c7e116",
            "1c390daf5de54dd486cd57f075e4a803",
            "abbb8610e3e94b0094017a261640ed72",
            "05d9c314b87d4a85bba18570fea8c43c",
            "3951c9a437164b9cb9ae5e2e661efd3c",
            "37481e02e5544ff2bc42b6ba4b8579c4",
            "0dc6b016079e4bb8934665a0ebce5da1",
            "33ed53cdaac04ac5b1a1d7795f585156",
            "e041cfae81a447809351d5d4aa30b973",
            "3ca3ca5dc3b64700ae6b54e6d565bc84",
            "5e7c56ce480a47e987adb0e913c3cd41",
            "f544f40ba5a14358b279ce6dbf2b67e5",
            "504dca74e6ef4bb3b9314952347f2874",
            "1342d9c5693649229012295c0f859902",
            "f7bd4eac261a49dca47263e10753b84e",
            "ec9f1b33f30240af8bf1178640e1127e",
            "4bd042c4b7e74eb39539c2347974368f",
            "ee4ea8952e614cfea1e2b87725cb6377",
            "baa3dabbd8384f71a8376d64930ff601",
            "71e6714014f142519e9faa2d579240a6",
            "8b53afb33a1c406590842924f313ea6f",
            "0f1b28c6cb314705a313cbf28a665984",
            "79a96b0a1dbc42aaa669a9b01bd774f9",
            "5f4b6de0eb97442483007ceedda57acb",
            "ee30256d7d9c4f1582436469588b74a1",
            "ccee5afd802248a2ba2633e72d2230db",
            "bfdfde06a27c4fb9b4982147f17205fe",
            "ee83fff097b645abb718cc04a8686c54",
            "bcf283289be8497e93837372078f3730",
            "cc950b5a34ec438fba0e499a6ef17a20",
            "d1812749ee8148c8a70890d29522e714",
            "5e068267eec04b41b3c38586cd5bcab6",
            "7fa22f3d8f0b4547a501822a968f22c1",
            "904f5fe937de482db6c0085e6040d038",
            "d9579af5e10149cb90a5c9ec5008d548",
            "afb85edce74e40559c21a4e834fc93d7",
            "000b3a0acedf4c48a163ad6df46052f5",
            "03be5d7298b34a30b9eac04188ae1959",
            "29ef33bf22cc4cd9ab093ab3e7f45825",
            "3a8ac25b7c4748cb9ea3db64f2a8cdc9",
            "864311f675dd4e19844869d4dfeac5f0",
            "465507aeaf3547c58be7fefdc8175b58",
            "3c2da21314ae41eabd175581dc1e3a8d"
          ]
        },
        "id": "qgjAADBFHB0S",
        "outputId": "a3d0818a-1baf-4471-fa20-771a4f3255ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cbdd13e42eb4b24901b34daa35579d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "params.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e7c56ce480a47e987adb0e913c3cd41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "consolidated.safetensors:   0%|          | 0.00/14.5G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f1b28c6cb314705a313cbf28a665984"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model.v3:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fa22f3d8f0b4547a501822a968f22c1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "\n",
        "mistral_models_path = Path.home().joinpath('mistral_models', '7B-v0.3')\n",
        "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "snapshot_download(repo_id=\"mistralai/Mistral-7B-v0.3\", allow_patterns=[\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\"], local_dir=mistral_models_path)\n",
        "\n",
        "! cp -r /root/mistral_models/7B-v0.3 /content/mistral_models\n",
        "! rm -r /root/mistral_models/7B-v0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdl_R5baUyha",
        "outputId": "8ddcc9d2-5088-47a8-b5f7-d73c89063246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-24 18:50:25--  https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar\n",
            "Resolving models.mistralcdn.com (models.mistralcdn.com)... 104.26.6.117, 104.26.7.117, 172.67.70.68, ...\n",
            "Connecting to models.mistralcdn.com (models.mistralcdn.com)|104.26.6.117|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14496675840 (14G) [application/x-tar]\n",
            "Saving to: ‘mistral-7B-v0.3.tar’\n",
            "\n",
            "mistral-7B-v0.3.tar 100%[===================>]  13.50G  40.5MB/s    in 6m 3s   \n",
            "\n",
            "2024-05-24 18:56:29 (38.1 MB/s) - ‘mistral-7B-v0.3.tar’ saved [14496675840/14496675840]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Alternatively, you can download the model from mistral\n",
        "\n",
        "# !wget https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-v0.3.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgJWR-fReilz"
      },
      "outputs": [],
      "source": [
        "# !DIR=/content/mistral_models && mkdir -p $DIR && tar -xf mistral-7B-v0.3.tar -C $DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PxYGmcy4gu0",
        "outputId": "4d865ba6-0eb5-40a5-a7b1-25dcf3ba36e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "consolidated.safetensors  params.json  tokenizer.model.v3\n"
          ]
        }
      ],
      "source": [
        "!ls /content/mistral_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ams-19wF8zgY"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "To ensure effective training, mistral-finetune has strict requirements for how the training data has to be formatted. Check out the required data formatting [here](https://github.com/mistralai/mistral-finetune/tree/main?tab=readme-ov-file#prepare-dataset).\n",
        "\n",
        "In this example, let’s use the ultrachat_200k dataset. We load a chunk of the data into Pandas Dataframes, split the data into training and validation, and save the data into the required `jsonl` format for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T33N2SwCIhEl",
        "outputId": "9d98c215-3e0e-46d9-c734-3c6aad5ce46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i7bmgXvG1vUq"
      },
      "outputs": [],
      "source": [
        "# make a new directory called data\n",
        "!mkdir -p data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br2czKwwFLE8",
        "outputId": "747d7f10-1063-40fa-dcc9-320721078871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ],
      "source": [
        "# navigate to this data directory\n",
        "%cd /content/data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/baggettersol/ct_train_full/resolve/main/ct-training.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AHfxMZzKtOX",
        "outputId": "22bede6d-6568-4697-e40f-a86d445cb412"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-23 02:49:45--  https://huggingface.co/datasets/baggettersol/ct_train_full/resolve/main/ct-training.jsonl\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.110, 3.166.152.105, 3.166.152.44, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/68d1f59b477c8090d3538a82/e2dd4c31ec856f0030723ece8ffadee47e676ced09975ad032196204ce6ff5b5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250923T024945Z&X-Amz-Expires=3600&X-Amz-Signature=58e0f8c6a8cc95e86a540814fbd2221986180eab37a5981fc2f37708eaf08d4a&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ct-training.jsonl%3B+filename%3D%22ct-training.jsonl%22%3B&x-id=GetObject&Expires=1758599385&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODU5OTM4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGQxZjU5YjQ3N2M4MDkwZDM1MzhhODIvZTJkZDRjMzFlYzg1NmYwMDMwNzIzZWNlOGZmYWRlZTQ3ZTY3NmNlZDA5OTc1YWQwMzIxOTYyMDRjZTZmZjViNSoifV19&Signature=aCWECb5noom7ib3cDqg56KZuy9B6YUSuYFzR2BAXEPhHstqdAupFhGFlFSU9w1Pi6HCa-pJkKz46YUPsVKydE%7EkVIWKB5eknSi5ZT1EnAYAXnJCASqPJN42TaLuZgdAwl3PYUmFyQe9eXPwmkYu2pBE8-u-YNORLcXmNECMjGOpvQmKyID6%7E9opypu9KTASBDjZY0uveUqSQBLbNyEt7L8lKJLhZeIDdwOGSypGZvhrWvncHhktbYoKt-SNjxqRqM6q9UTmZd8Ykx3gcZ-W6n4xlZSq0RXTnEQw7Q4TrzQQvI9R-A1PW3W%7EglUWzPrYx6beUDOKgq5qA%7Er9jnvBR1w__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-09-23 02:49:45--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68d1f59b477c8090d3538a82/e2dd4c31ec856f0030723ece8ffadee47e676ced09975ad032196204ce6ff5b5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250923%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250923T024945Z&X-Amz-Expires=3600&X-Amz-Signature=58e0f8c6a8cc95e86a540814fbd2221986180eab37a5981fc2f37708eaf08d4a&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ct-training.jsonl%3B+filename%3D%22ct-training.jsonl%22%3B&x-id=GetObject&Expires=1758599385&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODU5OTM4NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGQxZjU5YjQ3N2M4MDkwZDM1MzhhODIvZTJkZDRjMzFlYzg1NmYwMDMwNzIzZWNlOGZmYWRlZTQ3ZTY3NmNlZDA5OTc1YWQwMzIxOTYyMDRjZTZmZjViNSoifV19&Signature=aCWECb5noom7ib3cDqg56KZuy9B6YUSuYFzR2BAXEPhHstqdAupFhGFlFSU9w1Pi6HCa-pJkKz46YUPsVKydE%7EkVIWKB5eknSi5ZT1EnAYAXnJCASqPJN42TaLuZgdAwl3PYUmFyQe9eXPwmkYu2pBE8-u-YNORLcXmNECMjGOpvQmKyID6%7E9opypu9KTASBDjZY0uveUqSQBLbNyEt7L8lKJLhZeIDdwOGSypGZvhrWvncHhktbYoKt-SNjxqRqM6q9UTmZd8Ykx3gcZ-W6n4xlZSq0RXTnEQw7Q4TrzQQvI9R-A1PW3W%7EglUWzPrYx6beUDOKgq5qA%7Er9jnvBR1w__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.64.174.115, 18.64.174.83, 18.64.174.77, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.64.174.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 57735399 (55M)\n",
            "Saving to: ‘ct-training.jsonl’\n",
            "\n",
            "ct-training.jsonl   100%[===================>]  55.06M   132MB/s    in 0.4s    \n",
            "\n",
            "2025-09-23 02:49:46 (132 MB/s) - ‘ct-training.jsonl’ saved [57735399/57735399]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIK0VFXHIn8r",
        "outputId": "590d5ad8-b772-4014-9ea2-bcab4734572f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mistral-finetune\n"
          ]
        }
      ],
      "source": [
        "# navigate to the mistral-finetune directory\n",
        "%cd /content/mistral-finetune/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hia7n0T1_mHZ"
      },
      "source": [
        "## Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZtcLerooWFeB"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "# these info is needed for training\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5dxTlIQMaJGv"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "source activate myenv\n",
        "python3 -<<'EOF'\n",
        "# define training configuration\n",
        "# for your own use cases, you might want to change the data paths, model path, run_dir, and other hyperparameters\n",
        "\n",
        "config = \"\"\"\n",
        "# data\n",
        "data:\n",
        "  instruct_data: \"/content/data/ct-training.jsonl\"  # Fill\n",
        "  data: \"\"  # Optionally fill with pretraining data\n",
        "  eval_instruct_data: \"\"  # Optionally fill\n",
        "\n",
        "# model\n",
        "model_id_or_path: \"/content/mistral_models\"  # Change to downloaded path\n",
        "lora:\n",
        "  rank: 112\n",
        "\n",
        "# optim\n",
        "# tokens per training steps = batch_size x num_GPUs x seq_len\n",
        "# we recommend sequence length of 32768\n",
        "# If you run into memory error, you can try reduce the sequence length\n",
        "seq_len: 8192\n",
        "batch_size: 1\n",
        "num_microbatches: 8\n",
        "max_steps: 400\n",
        "optim:\n",
        "  lr: 1.e-4\n",
        "  weight_decay: 0.1\n",
        "  pct_start: 0.05\n",
        "\n",
        "# other\n",
        "seed: 0\n",
        "log_freq: 1\n",
        "eval_freq: 100\n",
        "no_eval: True\n",
        "ckpt_freq: 100\n",
        "\n",
        "save_adapters: True  # save only trained LoRA adapters. Set to `False` to merge LoRA adapter into the base model and save full fine-tuned model\n",
        "\n",
        "run_dir: \"/content/test_ultra\"  # Fill\n",
        "\"\"\"\n",
        "\n",
        "# save the same file locally into the example.yaml file\n",
        "import yaml\n",
        "with open('example.yaml', 'w') as file:\n",
        "    yaml.dump(yaml.safe_load(config), file)\n",
        "EOF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downgrade numpy\n",
        "%%bash\n",
        "source activate myenv\n",
        "\n",
        "pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXuy_mbgOozs",
        "outputId": "e893253c-8312-4569-828f-24107cc6b73e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/envs/myenv/lib/python3.10/site-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fix that mistral bs\n",
        "\n",
        "!conda run -n myenv python -m pip install mistral-common==1.3.1 --force-reinstall"
      ],
      "metadata": {
        "id": "WZqfbHfTPQbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /usr/local/envs/myenv/etc/conda/activate.d\n",
        "!echo 'export CUDA_VISIBLE_DEVICES=0' > /usr/local/envs/myenv/etc/conda/activate.d/env_vars.sh"
      ],
      "metadata": {
        "id": "9tTniLMGP9KQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ErD1ktQUMyPZ"
      },
      "outputs": [],
      "source": [
        "# make sure the run_dir has not been created before\n",
        "# only run this when you ran torchrun previously and created the /content/test_ultra file\n",
        "!rm -r /content/test_ultra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4wFgmwIUTtg",
        "outputId": "ff35c6cc-483a-41e7-ff26-b91ba0bf4c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args: TrainArgs(data=DataArgs(data='', shuffle=False, instruct_data='/content/data/ct-training.jsonl', eval_instruct_data='', instruct=InstructArgs(shuffle=True, dynamic_chunk_fn_call=True)), model_id_or_path='/content/mistral_models', run_dir='/content/test_ultra', optim=OptimArgs(lr=0.0001, weight_decay=0.1, pct_start=0.05), seed=0, num_microbatches=8, seq_len=8192, batch_size=1, max_norm=1.0, max_steps=400, log_freq=1, ckpt_freq=100, save_adapters=True, no_ckpt=False, num_ckpt_keep=3, eval_freq=100, no_eval=True, checkpoint=True, world_size=1, wandb=WandbArgs(project=None, offline=False, key=None, run_name=None), mlflow=MLFlowArgs(tracking_uri=None, experiment_name=None), lora=LoraArgs(enable=True, rank=112, dropout=0.0, scaling=2.0))\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:02 - distributed - INFO - torch.cuda.device_count: 1\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:02 - distributed - INFO - CUDA_VISIBLE_DEVICES: 0\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:02 - distributed - INFO - local rank: 0\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:02 - train - INFO - Going to init comms...\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:02 - train - INFO - Run dir: /content/test_ultra\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:02 - train - INFO - TrainArgs: {'batch_size': 1,\n",
            " 'checkpoint': True,\n",
            " 'ckpt_freq': 100,\n",
            " 'data': {'data': '',\n",
            "          'eval_instruct_data': '',\n",
            "          'instruct': {'dynamic_chunk_fn_call': True, 'shuffle': True},\n",
            "          'instruct_data': '/content/data/ct-training.jsonl',\n",
            "          'shuffle': False},\n",
            " 'eval_freq': 100,\n",
            " 'log_freq': 1,\n",
            " 'lora': {'dropout': 0.0, 'enable': True, 'rank': 112, 'scaling': 2.0},\n",
            " 'max_norm': 1.0,\n",
            " 'max_steps': 400,\n",
            " 'mlflow': {'experiment_name': None, 'tracking_uri': None},\n",
            " 'model_id_or_path': '/content/mistral_models',\n",
            " 'no_ckpt': False,\n",
            " 'no_eval': True,\n",
            " 'num_ckpt_keep': 3,\n",
            " 'num_microbatches': 8,\n",
            " 'optim': {'lr': 0.0001, 'pct_start': 0.05, 'weight_decay': 0.1},\n",
            " 'run_dir': '/content/test_ultra',\n",
            " 'save_adapters': True,\n",
            " 'seed': 0,\n",
            " 'seq_len': 8192,\n",
            " 'wandb': {'key': None, 'offline': False, 'project': None, 'run_name': None},\n",
            " 'world_size': 1}\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:03 - finetune.wrapped_model - INFO - Reloading model from /content/mistral_models/consolidated.safetensors ...\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:03 - finetune.wrapped_model - INFO - Converting model to dtype torch.bfloat16 ...\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:03 - finetune.wrapped_model - INFO - Loaded model on cpu!\n",
            "2025-09-23 02:50:22 (UTC) - 0:00:03 - finetune.wrapped_model - INFO - Initializing lora layers ...\n",
            "2025-09-23 02:50:24 (UTC) - 0:00:04 - finetune.wrapped_model - INFO - Finished initialization!\n",
            "2025-09-23 02:50:24 (UTC) - 0:00:04 - finetune.wrapped_model - INFO - Sharding model over 1 GPUs ...\n",
            "2025-09-23 02:50:29 (UTC) - 0:00:09 - finetune.wrapped_model - INFO - Model sharded!\n",
            "2025-09-23 02:50:29 (UTC) - 0:00:09 - finetune.wrapped_model - INFO - 293,601,280 out of 7,541,624,832 parameters are finetuned (3.89%).\n",
            "2025-09-23 02:50:29 (UTC) - 0:00:09 - dataset - INFO - Loading /content/data/ct-training.jsonl ...\n",
            "2025-09-23 02:51:23 (UTC) - 0:01:03 - dataset - INFO - /content/data/ct-training.jsonl loaded and tokenized.\n",
            "2025-09-23 02:51:23 (UTC) - 0:01:03 - dataset - INFO - Shuffling /content/data/ct-training.jsonl ...\n",
            "2025-09-23 02:51:42 (UTC) - 0:01:22 - train - INFO - step: 000001 - done (%): 0.2 - loss: 3.842 - lr: 4.0e-06 - peak_alloc_mem (GB): 21.9 - alloc_mem (GB): 19.0 - words_per_second: 902.1 - avg_words_per_second: 902.1 - ETA: >2025-09-23 10:54:48\n",
            "2025-09-23 02:52:00 (UTC) - 0:01:40 - train - INFO - step: 000002 - done (%): 0.5 - loss: 3.740 - lr: 4.7e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3651.0 - avg_words_per_second: 1446.7 - ETA: >2025-09-23 07:52:29\n",
            "2025-09-23 02:52:19 (UTC) - 0:01:59 - train - INFO - step: 000003 - done (%): 0.8 - loss: 3.578 - lr: 6.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3441.4 - avg_words_per_second: 1793.2 - ETA: >2025-09-23 06:54:08\n",
            "2025-09-23 02:52:37 (UTC) - 0:02:17 - train - INFO - step: 000004 - done (%): 1.0 - loss: 3.377 - lr: 9.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3637.2 - avg_words_per_second: 2053.4 - ETA: >2025-09-23 06:23:15\n",
            "2025-09-23 02:52:55 (UTC) - 0:02:35 - train - INFO - step: 000005 - done (%): 1.2 - loss: 3.139 - lr: 1.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3632.8 - avg_words_per_second: 2249.0 - ETA: >2025-09-23 06:04:45\n",
            "2025-09-23 02:53:14 (UTC) - 0:02:54 - train - INFO - step: 000006 - done (%): 1.5 - loss: 2.834 - lr: 1.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3365.9 - avg_words_per_second: 2380.7 - ETA: >2025-09-23 05:54:00\n",
            "2025-09-23 02:53:32 (UTC) - 0:03:12 - train - INFO - step: 000007 - done (%): 1.8 - loss: 2.549 - lr: 2.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3632.0 - avg_words_per_second: 2503.9 - ETA: >2025-09-23 05:44:58\n",
            "2025-09-23 02:53:50 (UTC) - 0:03:31 - train - INFO - step: 000008 - done (%): 2.0 - loss: 2.301 - lr: 3.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.0 - avg_words_per_second: 2604.6 - ETA: >2025-09-23 05:38:14\n",
            "2025-09-23 02:54:10 (UTC) - 0:03:50 - train - INFO - step: 000009 - done (%): 2.2 - loss: 2.016 - lr: 4.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3399.2 - avg_words_per_second: 2674.0 - ETA: >2025-09-23 05:33:52\n",
            "2025-09-23 02:54:28 (UTC) - 0:04:08 - train - INFO - step: 000010 - done (%): 2.5 - loss: 1.673 - lr: 4.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.9 - avg_words_per_second: 2746.3 - ETA: >2025-09-23 05:29:34\n",
            "2025-09-23 02:54:46 (UTC) - 0:04:26 - train - INFO - step: 000011 - done (%): 2.8 - loss: 1.435 - lr: 5.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.0 - avg_words_per_second: 2808.3 - ETA: >2025-09-23 05:26:04\n",
            "2025-09-23 02:55:05 (UTC) - 0:04:45 - train - INFO - step: 000012 - done (%): 3.0 - loss: 1.288 - lr: 6.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3393.1 - avg_words_per_second: 2849.2 - ETA: >2025-09-23 05:23:50\n",
            "2025-09-23 02:55:23 (UTC) - 0:05:03 - train - INFO - step: 000013 - done (%): 3.2 - loss: 1.161 - lr: 7.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.3 - avg_words_per_second: 2897.0 - ETA: >2025-09-23 05:21:18\n",
            "2025-09-23 02:55:41 (UTC) - 0:05:21 - train - INFO - step: 000014 - done (%): 3.5 - loss: 1.113 - lr: 7.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.0 - avg_words_per_second: 2939.2 - ETA: >2025-09-23 05:19:08\n",
            "2025-09-23 02:56:00 (UTC) - 0:05:41 - train - INFO - step: 000015 - done (%): 3.8 - loss: 1.068 - lr: 8.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3393.0 - avg_words_per_second: 2965.7 - ETA: >2025-09-23 05:17:48\n",
            "2025-09-23 02:56:18 (UTC) - 0:05:59 - train - INFO - step: 000016 - done (%): 4.0 - loss: 1.041 - lr: 9.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.6 - avg_words_per_second: 3000.0 - ETA: >2025-09-23 05:16:07\n",
            "2025-09-23 02:56:37 (UTC) - 0:06:17 - train - INFO - step: 000017 - done (%): 4.2 - loss: 1.104 - lr: 9.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.0 - avg_words_per_second: 3030.5 - ETA: >2025-09-23 05:14:39\n",
            "2025-09-23 02:56:56 (UTC) - 0:06:36 - train - INFO - step: 000018 - done (%): 4.5 - loss: 1.067 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3391.5 - avg_words_per_second: 3048.5 - ETA: >2025-09-23 05:13:48\n",
            "2025-09-23 02:57:14 (UTC) - 0:06:54 - train - INFO - step: 000019 - done (%): 4.8 - loss: 1.141 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.2 - avg_words_per_second: 3074.1 - ETA: >2025-09-23 05:12:36\n",
            "2025-09-23 02:57:32 (UTC) - 0:07:12 - train - INFO - step: 000020 - done (%): 5.0 - loss: 1.070 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.1 - avg_words_per_second: 3097.7 - ETA: >2025-09-23 05:11:32\n",
            "2025-09-23 02:57:52 (UTC) - 0:07:32 - train - INFO - step: 000021 - done (%): 5.2 - loss: 1.062 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3364.9 - avg_words_per_second: 3109.4 - ETA: >2025-09-23 05:11:00\n",
            "2025-09-23 02:58:10 (UTC) - 0:07:50 - train - INFO - step: 000022 - done (%): 5.5 - loss: 0.990 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.9 - avg_words_per_second: 3129.7 - ETA: >2025-09-23 05:10:05\n",
            "2025-09-23 02:58:28 (UTC) - 0:08:08 - train - INFO - step: 000023 - done (%): 5.8 - loss: 1.078 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.7 - avg_words_per_second: 3148.4 - ETA: >2025-09-23 05:09:15\n",
            "2025-09-23 02:58:47 (UTC) - 0:08:27 - train - INFO - step: 000024 - done (%): 6.0 - loss: 0.964 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3392.1 - avg_words_per_second: 3157.8 - ETA: >2025-09-23 05:08:50\n",
            "2025-09-23 02:59:05 (UTC) - 0:08:45 - train - INFO - step: 000025 - done (%): 6.2 - loss: 1.034 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.3 - avg_words_per_second: 3174.2 - ETA: >2025-09-23 05:08:08\n",
            "2025-09-23 02:59:23 (UTC) - 0:09:04 - train - INFO - step: 000026 - done (%): 6.5 - loss: 1.011 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.6 - avg_words_per_second: 3189.2 - ETA: >2025-09-23 05:07:29\n",
            "2025-09-23 02:59:43 (UTC) - 0:09:23 - train - INFO - step: 000027 - done (%): 6.8 - loss: 1.002 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3386.3 - avg_words_per_second: 3196.1 - ETA: >2025-09-23 05:07:11\n",
            "2025-09-23 03:00:01 (UTC) - 0:09:41 - train - INFO - step: 000028 - done (%): 7.0 - loss: 0.958 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.9 - avg_words_per_second: 3209.7 - ETA: >2025-09-23 05:06:36\n",
            "2025-09-23 03:00:19 (UTC) - 0:09:59 - train - INFO - step: 000029 - done (%): 7.2 - loss: 1.042 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.4 - avg_words_per_second: 3222.4 - ETA: >2025-09-23 05:06:04\n",
            "2025-09-23 03:00:38 (UTC) - 0:10:19 - train - INFO - step: 000030 - done (%): 7.5 - loss: 1.097 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3356.7 - avg_words_per_second: 3226.8 - ETA: >2025-09-23 05:05:53\n",
            "2025-09-23 03:00:56 (UTC) - 0:10:37 - train - INFO - step: 000031 - done (%): 7.8 - loss: 1.080 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.6 - avg_words_per_second: 3238.2 - ETA: >2025-09-23 05:05:24\n",
            "2025-09-23 03:01:14 (UTC) - 0:10:55 - train - INFO - step: 000032 - done (%): 8.0 - loss: 1.030 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.8 - avg_words_per_second: 3249.1 - ETA: >2025-09-23 05:04:57\n",
            "2025-09-23 03:01:34 (UTC) - 0:11:14 - train - INFO - step: 000033 - done (%): 8.2 - loss: 1.025 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3389.1 - avg_words_per_second: 3253.2 - ETA: >2025-09-23 05:04:47\n",
            "2025-09-23 03:01:52 (UTC) - 0:11:32 - train - INFO - step: 000034 - done (%): 8.5 - loss: 1.000 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.2 - avg_words_per_second: 3263.0 - ETA: >2025-09-23 05:04:23\n",
            "2025-09-23 03:02:10 (UTC) - 0:11:50 - train - INFO - step: 000035 - done (%): 8.8 - loss: 0.965 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.7 - avg_words_per_second: 3272.4 - ETA: >2025-09-23 05:04:00\n",
            "2025-09-23 03:02:29 (UTC) - 0:12:09 - train - INFO - step: 000036 - done (%): 9.0 - loss: 0.998 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3392.8 - avg_words_per_second: 3275.7 - ETA: >2025-09-23 05:03:52\n",
            "2025-09-23 03:02:47 (UTC) - 0:12:28 - train - INFO - step: 000037 - done (%): 9.2 - loss: 1.012 - lr: 1.0e-04 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3607.5 - avg_words_per_second: 3283.8 - ETA: >2025-09-23 05:03:32\n",
            "2025-09-23 03:03:05 (UTC) - 0:12:46 - train - INFO - step: 000038 - done (%): 9.5 - loss: 0.981 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.0 - avg_words_per_second: 3291.9 - ETA: >2025-09-23 05:03:12\n",
            "2025-09-23 03:03:25 (UTC) - 0:13:05 - train - INFO - step: 000039 - done (%): 9.8 - loss: 0.970 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3347.9 - avg_words_per_second: 3293.3 - ETA: >2025-09-23 05:03:09\n",
            "2025-09-23 03:03:43 (UTC) - 0:13:23 - train - INFO - step: 000040 - done (%): 10.0 - loss: 0.997 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.2 - avg_words_per_second: 3300.8 - ETA: >2025-09-23 05:02:51\n",
            "2025-09-23 03:04:01 (UTC) - 0:13:42 - train - INFO - step: 000041 - done (%): 10.2 - loss: 0.974 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.2 - avg_words_per_second: 3308.0 - ETA: >2025-09-23 05:02:33\n",
            "2025-09-23 03:04:21 (UTC) - 0:14:01 - train - INFO - step: 000042 - done (%): 10.5 - loss: 0.980 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3391.4 - avg_words_per_second: 3310.0 - ETA: >2025-09-23 05:02:29\n",
            "2025-09-23 03:04:39 (UTC) - 0:14:19 - train - INFO - step: 000043 - done (%): 10.8 - loss: 1.021 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.0 - avg_words_per_second: 3316.7 - ETA: >2025-09-23 05:02:13\n",
            "2025-09-23 03:04:57 (UTC) - 0:14:37 - train - INFO - step: 000044 - done (%): 11.0 - loss: 0.956 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.3 - avg_words_per_second: 3323.0 - ETA: >2025-09-23 05:01:58\n",
            "2025-09-23 03:05:16 (UTC) - 0:14:56 - train - INFO - step: 000045 - done (%): 11.2 - loss: 1.045 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3396.3 - avg_words_per_second: 3324.6 - ETA: >2025-09-23 05:01:54\n",
            "2025-09-23 03:05:34 (UTC) - 0:15:14 - train - INFO - step: 000046 - done (%): 11.5 - loss: 1.090 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.8 - avg_words_per_second: 3330.6 - ETA: >2025-09-23 05:01:40\n",
            "2025-09-23 03:05:52 (UTC) - 0:15:32 - train - INFO - step: 000047 - done (%): 11.8 - loss: 0.970 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.4 - avg_words_per_second: 3336.3 - ETA: >2025-09-23 05:01:26\n",
            "2025-09-23 03:06:11 (UTC) - 0:15:52 - train - INFO - step: 000048 - done (%): 12.0 - loss: 0.993 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3401.1 - avg_words_per_second: 3337.6 - ETA: >2025-09-23 05:01:23\n",
            "2025-09-23 03:06:30 (UTC) - 0:16:10 - train - INFO - step: 000049 - done (%): 12.2 - loss: 1.014 - lr: 9.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.3 - avg_words_per_second: 3343.1 - ETA: >2025-09-23 05:01:10\n",
            "2025-09-23 03:06:48 (UTC) - 0:16:28 - train - INFO - step: 000050 - done (%): 12.5 - loss: 1.032 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3629.2 - avg_words_per_second: 3348.4 - ETA: >2025-09-23 05:00:58\n",
            "2025-09-23 03:07:07 (UTC) - 0:16:47 - train - INFO - step: 000051 - done (%): 12.8 - loss: 0.997 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3356.3 - avg_words_per_second: 3348.5 - ETA: >2025-09-23 05:00:58\n",
            "2025-09-23 03:07:25 (UTC) - 0:17:06 - train - INFO - step: 000052 - done (%): 13.0 - loss: 0.954 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.4 - avg_words_per_second: 3353.4 - ETA: >2025-09-23 05:00:46\n",
            "2025-09-23 03:07:43 (UTC) - 0:17:24 - train - INFO - step: 000053 - done (%): 13.2 - loss: 0.939 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.4 - avg_words_per_second: 3357.9 - ETA: >2025-09-23 05:00:36\n",
            "2025-09-23 03:08:03 (UTC) - 0:17:43 - train - INFO - step: 000054 - done (%): 13.5 - loss: 1.003 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3396.7 - avg_words_per_second: 3358.7 - ETA: >2025-09-23 05:00:34\n",
            "2025-09-23 03:08:21 (UTC) - 0:18:01 - train - INFO - step: 000055 - done (%): 13.8 - loss: 0.955 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.5 - avg_words_per_second: 3363.1 - ETA: >2025-09-23 05:00:24\n",
            "2025-09-23 03:08:39 (UTC) - 0:18:19 - train - INFO - step: 000056 - done (%): 14.0 - loss: 0.945 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.5 - avg_words_per_second: 3367.4 - ETA: >2025-09-23 05:00:14\n",
            "2025-09-23 03:08:58 (UTC) - 0:18:38 - train - INFO - step: 000057 - done (%): 14.2 - loss: 1.053 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.6 - avg_words_per_second: 3367.8 - ETA: >2025-09-23 05:00:13\n",
            "2025-09-23 03:09:16 (UTC) - 0:18:57 - train - INFO - step: 000058 - done (%): 14.5 - loss: 1.012 - lr: 9.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.6 - avg_words_per_second: 3371.9 - ETA: >2025-09-23 05:00:03\n",
            "2025-09-23 03:09:34 (UTC) - 0:19:15 - train - INFO - step: 000059 - done (%): 14.8 - loss: 0.941 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.7 - avg_words_per_second: 3375.8 - ETA: >2025-09-23 04:59:54\n",
            "2025-09-23 03:09:52 (UTC) - 0:19:33 - train - INFO - step: 000060 - done (%): 15.0 - loss: 0.895 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.7 - avg_words_per_second: 3379.7 - ETA: >2025-09-23 04:59:46\n",
            "2025-09-23 03:10:12 (UTC) - 0:19:52 - train - INFO - step: 000061 - done (%): 15.2 - loss: 1.010 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3377.9 - avg_words_per_second: 3379.6 - ETA: >2025-09-23 04:59:46\n",
            "2025-09-23 03:10:30 (UTC) - 0:20:10 - train - INFO - step: 000062 - done (%): 15.5 - loss: 0.971 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.4 - avg_words_per_second: 3383.3 - ETA: >2025-09-23 04:59:37\n",
            "2025-09-23 03:10:48 (UTC) - 0:20:28 - train - INFO - step: 000063 - done (%): 15.8 - loss: 0.955 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.8 - avg_words_per_second: 3386.9 - ETA: >2025-09-23 04:59:29\n",
            "2025-09-23 03:11:08 (UTC) - 0:20:48 - train - INFO - step: 000064 - done (%): 16.0 - loss: 1.012 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3362.2 - avg_words_per_second: 3386.5 - ETA: >2025-09-23 04:59:30\n",
            "2025-09-23 03:11:26 (UTC) - 0:21:06 - train - INFO - step: 000065 - done (%): 16.2 - loss: 0.945 - lr: 9.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.8 - avg_words_per_second: 3389.9 - ETA: >2025-09-23 04:59:22\n",
            "2025-09-23 03:11:44 (UTC) - 0:21:24 - train - INFO - step: 000066 - done (%): 16.5 - loss: 0.974 - lr: 9.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.9 - avg_words_per_second: 3393.2 - ETA: >2025-09-23 04:59:15\n",
            "2025-09-23 03:12:03 (UTC) - 0:21:44 - train - INFO - step: 000067 - done (%): 16.8 - loss: 1.039 - lr: 9.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3348.6 - avg_words_per_second: 3392.5 - ETA: >2025-09-23 04:59:16\n",
            "2025-09-23 03:12:21 (UTC) - 0:22:02 - train - INFO - step: 000068 - done (%): 17.0 - loss: 0.938 - lr: 9.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.8 - avg_words_per_second: 3395.7 - ETA: >2025-09-23 04:59:09\n",
            "2025-09-23 03:12:40 (UTC) - 0:22:20 - train - INFO - step: 000069 - done (%): 17.2 - loss: 0.933 - lr: 9.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3616.0 - avg_words_per_second: 3398.7 - ETA: >2025-09-23 04:59:02\n",
            "2025-09-23 03:12:59 (UTC) - 0:22:39 - train - INFO - step: 000070 - done (%): 17.5 - loss: 0.956 - lr: 9.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3381.5 - avg_words_per_second: 3398.5 - ETA: >2025-09-23 04:59:03\n",
            "2025-09-23 03:13:17 (UTC) - 0:22:57 - train - INFO - step: 000071 - done (%): 17.8 - loss: 1.081 - lr: 9.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.5 - avg_words_per_second: 3401.5 - ETA: >2025-09-23 04:58:56\n",
            "2025-09-23 03:13:35 (UTC) - 0:23:15 - train - INFO - step: 000072 - done (%): 18.0 - loss: 0.963 - lr: 9.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.9 - avg_words_per_second: 3404.4 - ETA: >2025-09-23 04:58:49\n",
            "2025-09-23 03:13:55 (UTC) - 0:23:35 - train - INFO - step: 000073 - done (%): 18.2 - loss: 0.923 - lr: 9.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3357.3 - avg_words_per_second: 3403.7 - ETA: >2025-09-23 04:58:51\n",
            "2025-09-23 03:14:13 (UTC) - 0:23:53 - train - INFO - step: 000074 - done (%): 18.5 - loss: 0.926 - lr: 9.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.5 - avg_words_per_second: 3406.5 - ETA: >2025-09-23 04:58:44\n",
            "2025-09-23 03:14:31 (UTC) - 0:24:11 - train - INFO - step: 000075 - done (%): 18.8 - loss: 0.913 - lr: 9.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.8 - avg_words_per_second: 3409.3 - ETA: >2025-09-23 04:58:38\n",
            "2025-09-23 03:14:50 (UTC) - 0:24:30 - train - INFO - step: 000076 - done (%): 19.0 - loss: 0.940 - lr: 9.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3379.0 - avg_words_per_second: 3408.9 - ETA: >2025-09-23 04:58:39\n",
            "2025-09-23 03:15:08 (UTC) - 0:24:48 - train - INFO - step: 000077 - done (%): 19.2 - loss: 0.919 - lr: 9.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.5 - avg_words_per_second: 3411.5 - ETA: >2025-09-23 04:58:33\n",
            "2025-09-23 03:15:26 (UTC) - 0:25:07 - train - INFO - step: 000078 - done (%): 19.5 - loss: 0.965 - lr: 9.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.9 - avg_words_per_second: 3414.0 - ETA: >2025-09-23 04:58:28\n",
            "2025-09-23 03:15:46 (UTC) - 0:25:26 - train - INFO - step: 000079 - done (%): 19.8 - loss: 0.986 - lr: 9.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3369.3 - avg_words_per_second: 3413.4 - ETA: >2025-09-23 04:58:29\n",
            "2025-09-23 03:16:04 (UTC) - 0:25:44 - train - INFO - step: 000080 - done (%): 20.0 - loss: 1.063 - lr: 9.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.3 - avg_words_per_second: 3415.9 - ETA: >2025-09-23 04:58:23\n",
            "2025-09-23 03:16:22 (UTC) - 0:26:02 - train - INFO - step: 000081 - done (%): 20.2 - loss: 0.989 - lr: 9.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.6 - avg_words_per_second: 3418.2 - ETA: >2025-09-23 04:58:18\n",
            "2025-09-23 03:16:41 (UTC) - 0:26:22 - train - INFO - step: 000082 - done (%): 20.5 - loss: 0.913 - lr: 9.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3398.6 - avg_words_per_second: 3418.0 - ETA: >2025-09-23 04:58:19\n",
            "2025-09-23 03:16:59 (UTC) - 0:26:40 - train - INFO - step: 000083 - done (%): 20.8 - loss: 0.924 - lr: 9.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.1 - avg_words_per_second: 3420.3 - ETA: >2025-09-23 04:58:13\n",
            "2025-09-23 03:17:17 (UTC) - 0:26:58 - train - INFO - step: 000084 - done (%): 21.0 - loss: 1.014 - lr: 9.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.8 - avg_words_per_second: 3422.6 - ETA: >2025-09-23 04:58:08\n",
            "2025-09-23 03:17:37 (UTC) - 0:27:17 - train - INFO - step: 000085 - done (%): 21.2 - loss: 0.945 - lr: 9.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3390.6 - avg_words_per_second: 3422.2 - ETA: >2025-09-23 04:58:09\n",
            "2025-09-23 03:17:55 (UTC) - 0:27:35 - train - INFO - step: 000086 - done (%): 21.5 - loss: 0.933 - lr: 9.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3604.8 - avg_words_per_second: 3424.2 - ETA: >2025-09-23 04:58:05\n",
            "2025-09-23 03:18:13 (UTC) - 0:27:53 - train - INFO - step: 000087 - done (%): 21.8 - loss: 0.959 - lr: 9.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3616.5 - avg_words_per_second: 3426.3 - ETA: >2025-09-23 04:58:00\n",
            "2025-09-23 03:18:33 (UTC) - 0:28:13 - train - INFO - step: 000088 - done (%): 22.0 - loss: 0.957 - lr: 9.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3376.4 - avg_words_per_second: 3425.8 - ETA: >2025-09-23 04:58:01\n",
            "2025-09-23 03:18:51 (UTC) - 0:28:31 - train - INFO - step: 000089 - done (%): 22.2 - loss: 0.909 - lr: 9.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.2 - avg_words_per_second: 3427.9 - ETA: >2025-09-23 04:57:56\n",
            "2025-09-23 03:19:09 (UTC) - 0:28:49 - train - INFO - step: 000090 - done (%): 22.5 - loss: 0.954 - lr: 9.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.1 - avg_words_per_second: 3429.9 - ETA: >2025-09-23 04:57:52\n",
            "2025-09-23 03:19:28 (UTC) - 0:29:08 - train - INFO - step: 000091 - done (%): 22.8 - loss: 1.000 - lr: 9.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3372.3 - avg_words_per_second: 3429.3 - ETA: >2025-09-23 04:57:53\n",
            "2025-09-23 03:19:46 (UTC) - 0:29:26 - train - INFO - step: 000092 - done (%): 23.0 - loss: 0.887 - lr: 9.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.5 - avg_words_per_second: 3431.3 - ETA: >2025-09-23 04:57:49\n",
            "2025-09-23 03:20:04 (UTC) - 0:29:45 - train - INFO - step: 000093 - done (%): 23.2 - loss: 0.933 - lr: 9.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.2 - avg_words_per_second: 3433.3 - ETA: >2025-09-23 04:57:44\n",
            "2025-09-23 03:20:24 (UTC) - 0:30:04 - train - INFO - step: 000094 - done (%): 23.5 - loss: 1.031 - lr: 9.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3400.5 - avg_words_per_second: 3432.9 - ETA: >2025-09-23 04:57:45\n",
            "2025-09-23 03:20:42 (UTC) - 0:30:22 - train - INFO - step: 000095 - done (%): 23.8 - loss: 0.917 - lr: 9.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.9 - avg_words_per_second: 3434.8 - ETA: >2025-09-23 04:57:41\n",
            "2025-09-23 03:21:00 (UTC) - 0:30:40 - train - INFO - step: 000096 - done (%): 24.0 - loss: 0.994 - lr: 9.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.4 - avg_words_per_second: 3436.6 - ETA: >2025-09-23 04:57:37\n",
            "2025-09-23 03:21:19 (UTC) - 0:30:59 - train - INFO - step: 000097 - done (%): 24.2 - loss: 0.954 - lr: 9.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3386.4 - avg_words_per_second: 3436.1 - ETA: >2025-09-23 04:57:38\n",
            "2025-09-23 03:21:37 (UTC) - 0:31:17 - train - INFO - step: 000098 - done (%): 24.5 - loss: 0.924 - lr: 9.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.0 - avg_words_per_second: 3437.9 - ETA: >2025-09-23 04:57:34\n",
            "2025-09-23 03:21:55 (UTC) - 0:31:36 - train - INFO - step: 000099 - done (%): 24.8 - loss: 1.001 - lr: 9.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.6 - avg_words_per_second: 3439.7 - ETA: >2025-09-23 04:57:30\n",
            "2025-09-23 03:22:15 (UTC) - 0:31:55 - train - INFO - step: 000100 - done (%): 25.0 - loss: 1.028 - lr: 8.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3377.7 - avg_words_per_second: 3439.0 - ETA: >2025-09-23 04:57:32\n",
            "2025-09-23 03:22:15 (UTC) - 0:31:55 - checkpointing - INFO - Dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000100/consolidated using tmp name: tmp.consolidated\n",
            "2025-09-23 03:22:16 (UTC) - 0:31:56 - checkpointing - INFO - Done dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000100/consolidated for step: 100\n",
            "2025-09-23 03:22:16 (UTC) - 0:31:56 - checkpointing - INFO - Done deleting checkpoints \n",
            "2025-09-23 03:22:16 (UTC) - 0:31:56 - checkpointing - INFO - Done!\n",
            "2025-09-23 03:22:34 (UTC) - 0:32:14 - train - INFO - step: 000101 - done (%): 25.2 - loss: 0.912 - lr: 8.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.6 - avg_words_per_second: 3440.8 - ETA: >2025-09-23 04:57:29\n",
            "2025-09-23 03:22:52 (UTC) - 0:32:32 - train - INFO - step: 000102 - done (%): 25.5 - loss: 0.985 - lr: 8.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.4 - avg_words_per_second: 3442.6 - ETA: >2025-09-23 04:57:25\n",
            "2025-09-23 03:23:11 (UTC) - 0:32:51 - train - INFO - step: 000103 - done (%): 25.8 - loss: 1.056 - lr: 8.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3412.0 - avg_words_per_second: 3442.3 - ETA: >2025-09-23 04:57:26\n",
            "2025-09-23 03:23:29 (UTC) - 0:33:10 - train - INFO - step: 000104 - done (%): 26.0 - loss: 0.913 - lr: 8.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3443.9 - ETA: >2025-09-23 04:57:22\n",
            "2025-09-23 03:23:47 (UTC) - 0:33:28 - train - INFO - step: 000105 - done (%): 26.2 - loss: 0.957 - lr: 8.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.1 - avg_words_per_second: 3445.6 - ETA: >2025-09-23 04:57:18\n",
            "2025-09-23 03:24:07 (UTC) - 0:33:47 - train - INFO - step: 000106 - done (%): 26.5 - loss: 0.905 - lr: 8.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3379.6 - avg_words_per_second: 3444.9 - ETA: >2025-09-23 04:57:20\n",
            "2025-09-23 03:24:25 (UTC) - 0:34:05 - train - INFO - step: 000107 - done (%): 26.8 - loss: 0.924 - lr: 8.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.3 - avg_words_per_second: 3446.6 - ETA: >2025-09-23 04:57:16\n",
            "2025-09-23 03:24:43 (UTC) - 0:34:23 - train - INFO - step: 000108 - done (%): 27.0 - loss: 0.925 - lr: 8.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.4 - avg_words_per_second: 3448.1 - ETA: >2025-09-23 04:57:13\n",
            "2025-09-23 03:25:02 (UTC) - 0:34:43 - train - INFO - step: 000109 - done (%): 27.2 - loss: 1.028 - lr: 8.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3369.6 - avg_words_per_second: 3447.3 - ETA: >2025-09-23 04:57:14\n",
            "2025-09-23 03:25:20 (UTC) - 0:35:01 - train - INFO - step: 000110 - done (%): 27.5 - loss: 0.882 - lr: 8.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.8 - avg_words_per_second: 3448.9 - ETA: >2025-09-23 04:57:11\n",
            "2025-09-23 03:25:39 (UTC) - 0:35:19 - train - INFO - step: 000111 - done (%): 27.8 - loss: 0.953 - lr: 8.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3629.5 - avg_words_per_second: 3450.4 - ETA: >2025-09-23 04:57:08\n",
            "2025-09-23 03:25:58 (UTC) - 0:35:38 - train - INFO - step: 000112 - done (%): 28.0 - loss: 0.997 - lr: 8.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3365.2 - avg_words_per_second: 3449.6 - ETA: >2025-09-23 04:57:09\n",
            "2025-09-23 03:26:16 (UTC) - 0:35:56 - train - INFO - step: 000113 - done (%): 28.2 - loss: 0.910 - lr: 8.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.9 - avg_words_per_second: 3451.1 - ETA: >2025-09-23 04:57:06\n",
            "2025-09-23 03:26:34 (UTC) - 0:36:14 - train - INFO - step: 000114 - done (%): 28.5 - loss: 0.985 - lr: 8.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.5 - avg_words_per_second: 3452.5 - ETA: >2025-09-23 04:57:03\n",
            "2025-09-23 03:26:54 (UTC) - 0:36:34 - train - INFO - step: 000115 - done (%): 28.8 - loss: 0.992 - lr: 8.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.1 - avg_words_per_second: 3451.9 - ETA: >2025-09-23 04:57:04\n",
            "2025-09-23 03:27:12 (UTC) - 0:36:52 - train - INFO - step: 000116 - done (%): 29.0 - loss: 0.914 - lr: 8.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.1 - avg_words_per_second: 3453.3 - ETA: >2025-09-23 04:57:01\n",
            "2025-09-23 03:27:30 (UTC) - 0:37:10 - train - INFO - step: 000117 - done (%): 29.2 - loss: 0.932 - lr: 8.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.6 - avg_words_per_second: 3454.7 - ETA: >2025-09-23 04:56:58\n",
            "2025-09-23 03:27:49 (UTC) - 0:37:30 - train - INFO - step: 000118 - done (%): 29.5 - loss: 0.970 - lr: 8.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3339.4 - avg_words_per_second: 3453.7 - ETA: >2025-09-23 04:57:01\n",
            "2025-09-23 03:28:07 (UTC) - 0:37:48 - train - INFO - step: 000119 - done (%): 29.8 - loss: 0.978 - lr: 8.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.6 - avg_words_per_second: 3455.0 - ETA: >2025-09-23 04:56:58\n",
            "2025-09-23 03:28:26 (UTC) - 0:38:06 - train - INFO - step: 000120 - done (%): 30.0 - loss: 0.953 - lr: 8.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.6 - avg_words_per_second: 3456.4 - ETA: >2025-09-23 04:56:55\n",
            "2025-09-23 03:28:45 (UTC) - 0:38:25 - train - INFO - step: 000121 - done (%): 30.2 - loss: 0.927 - lr: 8.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3383.7 - avg_words_per_second: 3455.8 - ETA: >2025-09-23 04:56:56\n",
            "2025-09-23 03:29:03 (UTC) - 0:38:43 - train - INFO - step: 000122 - done (%): 30.5 - loss: 0.935 - lr: 8.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3457.1 - ETA: >2025-09-23 04:56:53\n",
            "2025-09-23 03:29:21 (UTC) - 0:39:01 - train - INFO - step: 000123 - done (%): 30.8 - loss: 1.002 - lr: 8.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3613.7 - avg_words_per_second: 3458.3 - ETA: >2025-09-23 04:56:50\n",
            "2025-09-23 03:29:40 (UTC) - 0:39:21 - train - INFO - step: 000124 - done (%): 31.0 - loss: 0.959 - lr: 8.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3400.0 - avg_words_per_second: 3457.8 - ETA: >2025-09-23 04:56:51\n",
            "2025-09-23 03:29:59 (UTC) - 0:39:39 - train - INFO - step: 000125 - done (%): 31.2 - loss: 0.961 - lr: 8.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.0 - avg_words_per_second: 3459.1 - ETA: >2025-09-23 04:56:49\n",
            "2025-09-23 03:30:17 (UTC) - 0:39:57 - train - INFO - step: 000126 - done (%): 31.5 - loss: 0.932 - lr: 8.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.8 - avg_words_per_second: 3460.3 - ETA: >2025-09-23 04:56:46\n",
            "2025-09-23 03:30:36 (UTC) - 0:40:16 - train - INFO - step: 000127 - done (%): 31.8 - loss: 0.861 - lr: 8.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3397.2 - avg_words_per_second: 3459.8 - ETA: >2025-09-23 04:56:47\n",
            "2025-09-23 03:30:54 (UTC) - 0:40:34 - train - INFO - step: 000128 - done (%): 32.0 - loss: 0.952 - lr: 8.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.0 - avg_words_per_second: 3461.0 - ETA: >2025-09-23 04:56:44\n",
            "2025-09-23 03:31:12 (UTC) - 0:40:52 - train - INFO - step: 000129 - done (%): 32.2 - loss: 0.893 - lr: 8.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3462.2 - ETA: >2025-09-23 04:56:42\n",
            "2025-09-23 03:31:31 (UTC) - 0:41:12 - train - INFO - step: 000130 - done (%): 32.5 - loss: 1.004 - lr: 8.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3375.7 - avg_words_per_second: 3461.6 - ETA: >2025-09-23 04:56:43\n",
            "2025-09-23 03:31:50 (UTC) - 0:41:30 - train - INFO - step: 000131 - done (%): 32.8 - loss: 0.966 - lr: 8.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.8 - avg_words_per_second: 3462.8 - ETA: >2025-09-23 04:56:41\n",
            "2025-09-23 03:32:08 (UTC) - 0:41:48 - train - INFO - step: 000132 - done (%): 33.0 - loss: 0.911 - lr: 8.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.2 - avg_words_per_second: 3463.9 - ETA: >2025-09-23 04:56:38\n",
            "2025-09-23 03:32:27 (UTC) - 0:42:07 - train - INFO - step: 000133 - done (%): 33.2 - loss: 0.915 - lr: 8.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3403.4 - avg_words_per_second: 3463.5 - ETA: >2025-09-23 04:56:39\n",
            "2025-09-23 03:32:45 (UTC) - 0:42:25 - train - INFO - step: 000134 - done (%): 33.5 - loss: 0.959 - lr: 7.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.1 - avg_words_per_second: 3464.6 - ETA: >2025-09-23 04:56:37\n",
            "2025-09-23 03:33:03 (UTC) - 0:42:43 - train - INFO - step: 000135 - done (%): 33.8 - loss: 0.796 - lr: 7.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.2 - avg_words_per_second: 3465.6 - ETA: >2025-09-23 04:56:34\n",
            "2025-09-23 03:33:22 (UTC) - 0:43:03 - train - INFO - step: 000136 - done (%): 34.0 - loss: 0.870 - lr: 7.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3395.6 - avg_words_per_second: 3465.1 - ETA: >2025-09-23 04:56:35\n",
            "2025-09-23 03:33:41 (UTC) - 0:43:21 - train - INFO - step: 000137 - done (%): 34.2 - loss: 0.878 - lr: 7.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.4 - avg_words_per_second: 3466.2 - ETA: >2025-09-23 04:56:33\n",
            "2025-09-23 03:33:59 (UTC) - 0:43:39 - train - INFO - step: 000138 - done (%): 34.5 - loss: 1.019 - lr: 7.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.1 - avg_words_per_second: 3467.3 - ETA: >2025-09-23 04:56:31\n",
            "2025-09-23 03:34:18 (UTC) - 0:43:58 - train - INFO - step: 000139 - done (%): 34.8 - loss: 0.934 - lr: 7.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3356.7 - avg_words_per_second: 3466.5 - ETA: >2025-09-23 04:56:33\n",
            "2025-09-23 03:34:36 (UTC) - 0:44:16 - train - INFO - step: 000140 - done (%): 35.0 - loss: 0.955 - lr: 7.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.2 - avg_words_per_second: 3467.6 - ETA: >2025-09-23 04:56:30\n",
            "2025-09-23 03:34:54 (UTC) - 0:44:35 - train - INFO - step: 000141 - done (%): 35.2 - loss: 0.982 - lr: 7.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.1 - avg_words_per_second: 3468.6 - ETA: >2025-09-23 04:56:28\n",
            "2025-09-23 03:35:14 (UTC) - 0:44:54 - train - INFO - step: 000142 - done (%): 35.5 - loss: 0.898 - lr: 7.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3393.3 - avg_words_per_second: 3468.1 - ETA: >2025-09-23 04:56:29\n",
            "2025-09-23 03:35:32 (UTC) - 0:45:12 - train - INFO - step: 000143 - done (%): 35.8 - loss: 0.920 - lr: 7.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.8 - avg_words_per_second: 3469.1 - ETA: >2025-09-23 04:56:27\n",
            "2025-09-23 03:35:50 (UTC) - 0:45:30 - train - INFO - step: 000144 - done (%): 36.0 - loss: 0.918 - lr: 7.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.0 - avg_words_per_second: 3470.2 - ETA: >2025-09-23 04:56:24\n",
            "2025-09-23 03:36:09 (UTC) - 0:45:49 - train - INFO - step: 000145 - done (%): 36.2 - loss: 0.980 - lr: 7.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.4 - avg_words_per_second: 3469.6 - ETA: >2025-09-23 04:56:26\n",
            "2025-09-23 03:36:27 (UTC) - 0:46:08 - train - INFO - step: 000146 - done (%): 36.5 - loss: 0.893 - lr: 7.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.5 - avg_words_per_second: 3470.6 - ETA: >2025-09-23 04:56:24\n",
            "2025-09-23 03:36:45 (UTC) - 0:46:26 - train - INFO - step: 000147 - done (%): 36.8 - loss: 0.934 - lr: 7.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.9 - avg_words_per_second: 3471.5 - ETA: >2025-09-23 04:56:22\n",
            "2025-09-23 03:37:05 (UTC) - 0:46:45 - train - INFO - step: 000148 - done (%): 37.0 - loss: 0.911 - lr: 7.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3351.6 - avg_words_per_second: 3470.7 - ETA: >2025-09-23 04:56:23\n",
            "2025-09-23 03:37:23 (UTC) - 0:47:03 - train - INFO - step: 000149 - done (%): 37.2 - loss: 1.024 - lr: 7.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.4 - avg_words_per_second: 3471.7 - ETA: >2025-09-23 04:56:21\n",
            "2025-09-23 03:37:41 (UTC) - 0:47:21 - train - INFO - step: 000150 - done (%): 37.5 - loss: 0.911 - lr: 7.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.2 - avg_words_per_second: 3472.6 - ETA: >2025-09-23 04:56:19\n",
            "2025-09-23 03:38:00 (UTC) - 0:47:41 - train - INFO - step: 000151 - done (%): 37.8 - loss: 0.994 - lr: 7.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.9 - avg_words_per_second: 3472.1 - ETA: >2025-09-23 04:56:20\n",
            "2025-09-23 03:38:18 (UTC) - 0:47:59 - train - INFO - step: 000152 - done (%): 38.0 - loss: 1.066 - lr: 7.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.0 - avg_words_per_second: 3473.1 - ETA: >2025-09-23 04:56:18\n",
            "2025-09-23 03:38:37 (UTC) - 0:48:17 - train - INFO - step: 000153 - done (%): 38.2 - loss: 0.884 - lr: 7.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3632.6 - avg_words_per_second: 3474.1 - ETA: >2025-09-23 04:56:16\n",
            "2025-09-23 03:38:56 (UTC) - 0:48:36 - train - INFO - step: 000154 - done (%): 38.5 - loss: 0.916 - lr: 7.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3391.7 - avg_words_per_second: 3473.5 - ETA: >2025-09-23 04:56:17\n",
            "2025-09-23 03:39:14 (UTC) - 0:48:54 - train - INFO - step: 000155 - done (%): 38.8 - loss: 0.958 - lr: 7.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.4 - avg_words_per_second: 3474.4 - ETA: >2025-09-23 04:56:15\n",
            "2025-09-23 03:39:32 (UTC) - 0:49:12 - train - INFO - step: 000156 - done (%): 39.0 - loss: 0.931 - lr: 7.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.5 - avg_words_per_second: 3475.3 - ETA: >2025-09-23 04:56:13\n",
            "2025-09-23 03:39:51 (UTC) - 0:49:32 - train - INFO - step: 000157 - done (%): 39.2 - loss: 0.888 - lr: 7.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3394.5 - avg_words_per_second: 3474.8 - ETA: >2025-09-23 04:56:14\n",
            "2025-09-23 03:39:56 (UTC) - 0:49:36 - dataset - INFO - Shuffling /content/data/ct-training.jsonl ...\n",
            "2025-09-23 03:40:09 (UTC) - 0:49:50 - train - INFO - step: 000158 - done (%): 39.5 - loss: 0.898 - lr: 7.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.4 - avg_words_per_second: 3475.7 - ETA: >2025-09-23 04:56:12\n",
            "2025-09-23 03:40:28 (UTC) - 0:50:08 - train - INFO - step: 000159 - done (%): 39.8 - loss: 0.830 - lr: 7.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.1 - avg_words_per_second: 3476.6 - ETA: >2025-09-23 04:56:11\n",
            "2025-09-23 03:40:47 (UTC) - 0:50:27 - train - INFO - step: 000160 - done (%): 40.0 - loss: 0.809 - lr: 7.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3360.4 - avg_words_per_second: 3475.8 - ETA: >2025-09-23 04:56:12\n",
            "2025-09-23 03:41:05 (UTC) - 0:50:45 - train - INFO - step: 000161 - done (%): 40.2 - loss: 0.756 - lr: 7.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.8 - avg_words_per_second: 3476.7 - ETA: >2025-09-23 04:56:10\n",
            "2025-09-23 03:41:23 (UTC) - 0:51:03 - train - INFO - step: 000162 - done (%): 40.5 - loss: 0.843 - lr: 6.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.4 - avg_words_per_second: 3477.6 - ETA: >2025-09-23 04:56:08\n",
            "2025-09-23 03:41:43 (UTC) - 0:51:23 - train - INFO - step: 000163 - done (%): 40.8 - loss: 0.788 - lr: 6.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3388.7 - avg_words_per_second: 3477.0 - ETA: >2025-09-23 04:56:10\n",
            "2025-09-23 03:42:01 (UTC) - 0:51:41 - train - INFO - step: 000164 - done (%): 41.0 - loss: 0.878 - lr: 6.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3633.1 - avg_words_per_second: 3477.9 - ETA: >2025-09-23 04:56:08\n",
            "2025-09-23 03:42:19 (UTC) - 0:51:59 - train - INFO - step: 000165 - done (%): 41.2 - loss: 0.739 - lr: 6.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.3 - avg_words_per_second: 3478.8 - ETA: >2025-09-23 04:56:06\n",
            "2025-09-23 03:42:38 (UTC) - 0:52:18 - train - INFO - step: 000166 - done (%): 41.5 - loss: 0.785 - lr: 6.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.7 - avg_words_per_second: 3478.2 - ETA: >2025-09-23 04:56:07\n",
            "2025-09-23 03:42:56 (UTC) - 0:52:36 - train - INFO - step: 000167 - done (%): 41.8 - loss: 0.757 - lr: 6.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.1 - avg_words_per_second: 3479.1 - ETA: >2025-09-23 04:56:05\n",
            "2025-09-23 03:43:14 (UTC) - 0:52:54 - train - INFO - step: 000168 - done (%): 42.0 - loss: 0.825 - lr: 6.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.5 - avg_words_per_second: 3479.9 - ETA: >2025-09-23 04:56:03\n",
            "2025-09-23 03:43:32 (UTC) - 0:53:13 - train - INFO - step: 000169 - done (%): 42.2 - loss: 0.822 - lr: 6.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.1 - avg_words_per_second: 3480.7 - ETA: >2025-09-23 04:56:02\n",
            "2025-09-23 03:43:52 (UTC) - 0:53:32 - train - INFO - step: 000170 - done (%): 42.5 - loss: 0.764 - lr: 6.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3378.8 - avg_words_per_second: 3480.1 - ETA: >2025-09-23 04:56:03\n",
            "2025-09-23 03:44:10 (UTC) - 0:53:50 - train - INFO - step: 000171 - done (%): 42.8 - loss: 0.781 - lr: 6.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.1 - avg_words_per_second: 3480.9 - ETA: >2025-09-23 04:56:01\n",
            "2025-09-23 03:44:28 (UTC) - 0:54:08 - train - INFO - step: 000172 - done (%): 43.0 - loss: 0.786 - lr: 6.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.2 - avg_words_per_second: 3481.8 - ETA: >2025-09-23 04:55:59\n",
            "2025-09-23 03:44:47 (UTC) - 0:54:28 - train - INFO - step: 000173 - done (%): 43.2 - loss: 0.790 - lr: 6.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3353.6 - avg_words_per_second: 3481.0 - ETA: >2025-09-23 04:56:01\n",
            "2025-09-23 03:45:05 (UTC) - 0:54:46 - train - INFO - step: 000174 - done (%): 43.5 - loss: 0.821 - lr: 6.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3614.9 - avg_words_per_second: 3481.7 - ETA: >2025-09-23 04:55:59\n",
            "2025-09-23 03:45:24 (UTC) - 0:55:04 - train - INFO - step: 000175 - done (%): 43.8 - loss: 0.762 - lr: 6.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.1 - avg_words_per_second: 3482.5 - ETA: >2025-09-23 04:55:58\n",
            "2025-09-23 03:45:43 (UTC) - 0:55:23 - train - INFO - step: 000176 - done (%): 44.0 - loss: 0.765 - lr: 6.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3356.2 - avg_words_per_second: 3481.7 - ETA: >2025-09-23 04:55:59\n",
            "2025-09-23 03:46:01 (UTC) - 0:55:41 - train - INFO - step: 000177 - done (%): 44.2 - loss: 0.732 - lr: 6.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.1 - avg_words_per_second: 3482.5 - ETA: >2025-09-23 04:55:58\n",
            "2025-09-23 03:46:19 (UTC) - 0:56:00 - train - INFO - step: 000178 - done (%): 44.5 - loss: 0.817 - lr: 6.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.9 - avg_words_per_second: 3483.3 - ETA: >2025-09-23 04:55:56\n",
            "2025-09-23 03:46:39 (UTC) - 0:56:19 - train - INFO - step: 000179 - done (%): 44.8 - loss: 0.750 - lr: 6.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3365.8 - avg_words_per_second: 3482.6 - ETA: >2025-09-23 04:55:58\n",
            "2025-09-23 03:46:57 (UTC) - 0:56:37 - train - INFO - step: 000180 - done (%): 45.0 - loss: 0.774 - lr: 6.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.5 - avg_words_per_second: 3483.3 - ETA: >2025-09-23 04:55:56\n",
            "2025-09-23 03:47:15 (UTC) - 0:56:55 - train - INFO - step: 000181 - done (%): 45.2 - loss: 0.845 - lr: 6.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.1 - avg_words_per_second: 3484.1 - ETA: >2025-09-23 04:55:54\n",
            "2025-09-23 03:47:35 (UTC) - 0:57:15 - train - INFO - step: 000182 - done (%): 45.5 - loss: 0.798 - lr: 6.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3353.0 - avg_words_per_second: 3483.3 - ETA: >2025-09-23 04:55:56\n",
            "2025-09-23 03:47:53 (UTC) - 0:57:33 - train - INFO - step: 000183 - done (%): 45.8 - loss: 0.747 - lr: 6.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.7 - avg_words_per_second: 3484.0 - ETA: >2025-09-23 04:55:54\n",
            "2025-09-23 03:48:11 (UTC) - 0:57:51 - train - INFO - step: 000184 - done (%): 46.0 - loss: 0.823 - lr: 6.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3629.9 - avg_words_per_second: 3484.8 - ETA: >2025-09-23 04:55:53\n",
            "2025-09-23 03:48:30 (UTC) - 0:58:10 - train - INFO - step: 000185 - done (%): 46.2 - loss: 0.786 - lr: 6.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3380.0 - avg_words_per_second: 3484.2 - ETA: >2025-09-23 04:55:54\n",
            "2025-09-23 03:48:48 (UTC) - 0:58:28 - train - INFO - step: 000186 - done (%): 46.5 - loss: 0.817 - lr: 6.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3631.9 - avg_words_per_second: 3485.0 - ETA: >2025-09-23 04:55:52\n",
            "2025-09-23 03:49:06 (UTC) - 0:58:46 - train - INFO - step: 000187 - done (%): 46.8 - loss: 0.781 - lr: 5.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3485.7 - ETA: >2025-09-23 04:55:51\n",
            "2025-09-23 03:49:26 (UTC) - 0:59:06 - train - INFO - step: 000188 - done (%): 47.0 - loss: 0.863 - lr: 5.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3375.6 - avg_words_per_second: 3485.1 - ETA: >2025-09-23 04:55:52\n",
            "2025-09-23 03:49:44 (UTC) - 0:59:24 - train - INFO - step: 000189 - done (%): 47.2 - loss: 0.771 - lr: 5.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.6 - avg_words_per_second: 3485.8 - ETA: >2025-09-23 04:55:51\n",
            "2025-09-23 03:50:02 (UTC) - 0:59:42 - train - INFO - step: 000190 - done (%): 47.5 - loss: 0.725 - lr: 5.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3486.5 - ETA: >2025-09-23 04:55:49\n",
            "2025-09-23 03:50:21 (UTC) - 1:00:01 - train - INFO - step: 000191 - done (%): 47.8 - loss: 0.779 - lr: 5.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3398.2 - avg_words_per_second: 3486.0 - ETA: >2025-09-23 04:55:50\n",
            "2025-09-23 03:50:39 (UTC) - 1:00:19 - train - INFO - step: 000192 - done (%): 48.0 - loss: 0.822 - lr: 5.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.8 - avg_words_per_second: 3486.7 - ETA: >2025-09-23 04:55:49\n",
            "2025-09-23 03:50:57 (UTC) - 1:00:37 - train - INFO - step: 000193 - done (%): 48.2 - loss: 0.752 - lr: 5.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.0 - avg_words_per_second: 3487.4 - ETA: >2025-09-23 04:55:47\n",
            "2025-09-23 03:51:17 (UTC) - 1:00:57 - train - INFO - step: 000194 - done (%): 48.5 - loss: 0.748 - lr: 5.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3390.3 - avg_words_per_second: 3486.9 - ETA: >2025-09-23 04:55:48\n",
            "2025-09-23 03:51:35 (UTC) - 1:01:15 - train - INFO - step: 000195 - done (%): 48.8 - loss: 0.764 - lr: 5.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.3 - avg_words_per_second: 3487.6 - ETA: >2025-09-23 04:55:47\n",
            "2025-09-23 03:51:53 (UTC) - 1:01:33 - train - INFO - step: 000196 - done (%): 49.0 - loss: 0.725 - lr: 5.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.3 - avg_words_per_second: 3488.2 - ETA: >2025-09-23 04:55:45\n",
            "2025-09-23 03:52:12 (UTC) - 1:01:52 - train - INFO - step: 000197 - done (%): 49.2 - loss: 0.745 - lr: 5.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3381.8 - avg_words_per_second: 3487.7 - ETA: >2025-09-23 04:55:47\n",
            "2025-09-23 03:52:30 (UTC) - 1:02:10 - train - INFO - step: 000198 - done (%): 49.5 - loss: 0.740 - lr: 5.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.3 - avg_words_per_second: 3488.4 - ETA: >2025-09-23 04:55:45\n",
            "2025-09-23 03:52:48 (UTC) - 1:02:29 - train - INFO - step: 000199 - done (%): 49.8 - loss: 0.733 - lr: 5.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.3 - avg_words_per_second: 3489.0 - ETA: >2025-09-23 04:55:44\n",
            "2025-09-23 03:53:08 (UTC) - 1:02:48 - train - INFO - step: 000200 - done (%): 50.0 - loss: 0.774 - lr: 5.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3368.8 - avg_words_per_second: 3488.4 - ETA: >2025-09-23 04:55:45\n",
            "2025-09-23 03:53:08 (UTC) - 1:02:48 - checkpointing - INFO - Dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000200/consolidated using tmp name: tmp.consolidated\n",
            "2025-09-23 03:53:09 (UTC) - 1:02:49 - checkpointing - INFO - Done dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000200/consolidated for step: 200\n",
            "2025-09-23 03:53:09 (UTC) - 1:02:49 - checkpointing - INFO - Done deleting checkpoints \n",
            "2025-09-23 03:53:09 (UTC) - 1:02:49 - checkpointing - INFO - Done!\n",
            "2025-09-23 03:53:27 (UTC) - 1:03:07 - train - INFO - step: 000201 - done (%): 50.2 - loss: 0.767 - lr: 5.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3614.6 - avg_words_per_second: 3489.0 - ETA: >2025-09-23 04:55:45\n",
            "2025-09-23 03:53:45 (UTC) - 1:03:25 - train - INFO - step: 000202 - done (%): 50.5 - loss: 0.786 - lr: 5.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.9 - avg_words_per_second: 3489.6 - ETA: >2025-09-23 04:55:44\n",
            "2025-09-23 03:54:04 (UTC) - 1:03:45 - train - INFO - step: 000203 - done (%): 50.8 - loss: 0.754 - lr: 5.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3376.0 - avg_words_per_second: 3489.0 - ETA: >2025-09-23 04:55:45\n",
            "2025-09-23 03:54:23 (UTC) - 1:04:03 - train - INFO - step: 000204 - done (%): 51.0 - loss: 0.823 - lr: 5.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.8 - avg_words_per_second: 3489.7 - ETA: >2025-09-23 04:55:43\n",
            "2025-09-23 03:54:41 (UTC) - 1:04:21 - train - INFO - step: 000205 - done (%): 51.2 - loss: 0.779 - lr: 5.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.0 - avg_words_per_second: 3490.3 - ETA: >2025-09-23 04:55:42\n",
            "2025-09-23 03:55:00 (UTC) - 1:04:40 - train - INFO - step: 000206 - done (%): 51.5 - loss: 0.777 - lr: 5.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3364.2 - avg_words_per_second: 3489.7 - ETA: >2025-09-23 04:55:43\n",
            "2025-09-23 03:55:18 (UTC) - 1:04:58 - train - INFO - step: 000207 - done (%): 51.8 - loss: 0.817 - lr: 5.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.4 - avg_words_per_second: 3490.3 - ETA: >2025-09-23 04:55:42\n",
            "2025-09-23 03:55:36 (UTC) - 1:05:17 - train - INFO - step: 000208 - done (%): 52.0 - loss: 0.839 - lr: 5.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.5 - avg_words_per_second: 3490.9 - ETA: >2025-09-23 04:55:41\n",
            "2025-09-23 03:55:56 (UTC) - 1:05:36 - train - INFO - step: 000209 - done (%): 52.2 - loss: 0.817 - lr: 5.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3347.1 - avg_words_per_second: 3490.2 - ETA: >2025-09-23 04:55:42\n",
            "2025-09-23 03:56:14 (UTC) - 1:05:54 - train - INFO - step: 000210 - done (%): 52.5 - loss: 0.749 - lr: 5.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.1 - avg_words_per_second: 3490.8 - ETA: >2025-09-23 04:55:41\n",
            "2025-09-23 03:56:32 (UTC) - 1:06:12 - train - INFO - step: 000211 - done (%): 52.8 - loss: 0.772 - lr: 5.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.9 - avg_words_per_second: 3491.4 - ETA: >2025-09-23 04:55:40\n",
            "2025-09-23 03:56:52 (UTC) - 1:06:32 - train - INFO - step: 000212 - done (%): 53.0 - loss: 0.750 - lr: 4.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3359.7 - avg_words_per_second: 3490.8 - ETA: >2025-09-23 04:55:41\n",
            "2025-09-23 03:57:10 (UTC) - 1:06:50 - train - INFO - step: 000213 - done (%): 53.2 - loss: 0.835 - lr: 4.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3491.4 - ETA: >2025-09-23 04:55:40\n",
            "2025-09-23 03:57:28 (UTC) - 1:07:08 - train - INFO - step: 000214 - done (%): 53.5 - loss: 0.786 - lr: 4.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.8 - avg_words_per_second: 3492.0 - ETA: >2025-09-23 04:55:38\n",
            "2025-09-23 03:57:47 (UTC) - 1:07:27 - train - INFO - step: 000215 - done (%): 53.8 - loss: 0.749 - lr: 4.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3398.0 - avg_words_per_second: 3491.5 - ETA: >2025-09-23 04:55:39\n",
            "2025-09-23 03:58:05 (UTC) - 1:07:45 - train - INFO - step: 000216 - done (%): 54.0 - loss: 0.790 - lr: 4.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.9 - avg_words_per_second: 3492.1 - ETA: >2025-09-23 04:55:38\n",
            "2025-09-23 03:58:23 (UTC) - 1:08:03 - train - INFO - step: 000217 - done (%): 54.2 - loss: 0.780 - lr: 4.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.1 - avg_words_per_second: 3492.7 - ETA: >2025-09-23 04:55:37\n",
            "2025-09-23 03:58:43 (UTC) - 1:08:23 - train - INFO - step: 000218 - done (%): 54.5 - loss: 0.823 - lr: 4.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3355.2 - avg_words_per_second: 3492.1 - ETA: >2025-09-23 04:55:38\n",
            "2025-09-23 03:59:01 (UTC) - 1:08:41 - train - INFO - step: 000219 - done (%): 54.8 - loss: 0.742 - lr: 4.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3608.7 - avg_words_per_second: 3492.6 - ETA: >2025-09-23 04:55:37\n",
            "2025-09-23 03:59:19 (UTC) - 1:08:59 - train - INFO - step: 000220 - done (%): 55.0 - loss: 0.731 - lr: 4.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3609.0 - avg_words_per_second: 3493.1 - ETA: >2025-09-23 04:55:36\n",
            "2025-09-23 03:59:38 (UTC) - 1:09:19 - train - INFO - step: 000221 - done (%): 55.2 - loss: 0.809 - lr: 4.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3393.2 - avg_words_per_second: 3492.6 - ETA: >2025-09-23 04:55:37\n",
            "2025-09-23 03:59:56 (UTC) - 1:09:37 - train - INFO - step: 000222 - done (%): 55.5 - loss: 0.770 - lr: 4.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.3 - avg_words_per_second: 3493.2 - ETA: >2025-09-23 04:55:36\n",
            "2025-09-23 04:00:15 (UTC) - 1:09:55 - train - INFO - step: 000223 - done (%): 55.8 - loss: 0.820 - lr: 4.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.4 - avg_words_per_second: 3493.8 - ETA: >2025-09-23 04:55:35\n",
            "2025-09-23 04:00:34 (UTC) - 1:10:14 - train - INFO - step: 000224 - done (%): 56.0 - loss: 0.747 - lr: 4.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3396.4 - avg_words_per_second: 3493.3 - ETA: >2025-09-23 04:55:36\n",
            "2025-09-23 04:00:52 (UTC) - 1:10:32 - train - INFO - step: 000225 - done (%): 56.2 - loss: 0.766 - lr: 4.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.0 - avg_words_per_second: 3493.9 - ETA: >2025-09-23 04:55:34\n",
            "2025-09-23 04:01:10 (UTC) - 1:10:50 - train - INFO - step: 000226 - done (%): 56.5 - loss: 0.790 - lr: 4.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.9 - avg_words_per_second: 3494.4 - ETA: >2025-09-23 04:55:33\n",
            "2025-09-23 04:01:29 (UTC) - 1:11:10 - train - INFO - step: 000227 - done (%): 56.8 - loss: 0.722 - lr: 4.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3384.4 - avg_words_per_second: 3493.9 - ETA: >2025-09-23 04:55:34\n",
            "2025-09-23 04:01:47 (UTC) - 1:11:28 - train - INFO - step: 000228 - done (%): 57.0 - loss: 0.791 - lr: 4.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.2 - avg_words_per_second: 3494.5 - ETA: >2025-09-23 04:55:33\n",
            "2025-09-23 04:02:06 (UTC) - 1:11:46 - train - INFO - step: 000229 - done (%): 57.2 - loss: 0.813 - lr: 4.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3614.6 - avg_words_per_second: 3495.0 - ETA: >2025-09-23 04:55:32\n",
            "2025-09-23 04:02:25 (UTC) - 1:12:05 - train - INFO - step: 000230 - done (%): 57.5 - loss: 0.740 - lr: 4.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3372.7 - avg_words_per_second: 3494.4 - ETA: >2025-09-23 04:55:33\n",
            "2025-09-23 04:02:43 (UTC) - 1:12:23 - train - INFO - step: 000231 - done (%): 57.8 - loss: 0.795 - lr: 4.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.4 - avg_words_per_second: 3495.0 - ETA: >2025-09-23 04:55:32\n",
            "2025-09-23 04:03:01 (UTC) - 1:12:41 - train - INFO - step: 000232 - done (%): 58.0 - loss: 0.787 - lr: 4.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.8 - avg_words_per_second: 3495.5 - ETA: >2025-09-23 04:55:31\n",
            "2025-09-23 04:03:21 (UTC) - 1:13:01 - train - INFO - step: 000233 - done (%): 58.2 - loss: 0.830 - lr: 4.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3364.1 - avg_words_per_second: 3494.9 - ETA: >2025-09-23 04:55:32\n",
            "2025-09-23 04:03:39 (UTC) - 1:13:19 - train - INFO - step: 000234 - done (%): 58.5 - loss: 0.748 - lr: 4.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.5 - avg_words_per_second: 3495.5 - ETA: >2025-09-23 04:55:31\n",
            "2025-09-23 04:03:57 (UTC) - 1:13:37 - train - INFO - step: 000235 - done (%): 58.8 - loss: 0.774 - lr: 4.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.7 - avg_words_per_second: 3496.0 - ETA: >2025-09-23 04:55:30\n",
            "2025-09-23 04:04:16 (UTC) - 1:13:57 - train - INFO - step: 000236 - done (%): 59.0 - loss: 0.782 - lr: 3.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3361.9 - avg_words_per_second: 3495.4 - ETA: >2025-09-23 04:55:31\n",
            "2025-09-23 04:04:34 (UTC) - 1:14:15 - train - INFO - step: 000237 - done (%): 59.2 - loss: 0.764 - lr: 3.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.9 - avg_words_per_second: 3495.9 - ETA: >2025-09-23 04:55:30\n",
            "2025-09-23 04:04:52 (UTC) - 1:14:33 - train - INFO - step: 000238 - done (%): 59.5 - loss: 0.777 - lr: 3.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.0 - avg_words_per_second: 3496.4 - ETA: >2025-09-23 04:55:29\n",
            "2025-09-23 04:05:12 (UTC) - 1:14:52 - train - INFO - step: 000239 - done (%): 59.8 - loss: 0.824 - lr: 3.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3355.4 - avg_words_per_second: 3495.8 - ETA: >2025-09-23 04:55:30\n",
            "2025-09-23 04:05:30 (UTC) - 1:15:10 - train - INFO - step: 000240 - done (%): 60.0 - loss: 0.758 - lr: 3.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.0 - avg_words_per_second: 3496.3 - ETA: >2025-09-23 04:55:29\n",
            "2025-09-23 04:05:48 (UTC) - 1:15:28 - train - INFO - step: 000241 - done (%): 60.2 - loss: 0.713 - lr: 3.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.8 - avg_words_per_second: 3496.8 - ETA: >2025-09-23 04:55:28\n",
            "2025-09-23 04:06:08 (UTC) - 1:15:48 - train - INFO - step: 000242 - done (%): 60.5 - loss: 0.843 - lr: 3.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3369.7 - avg_words_per_second: 3496.3 - ETA: >2025-09-23 04:55:29\n",
            "2025-09-23 04:06:26 (UTC) - 1:16:06 - train - INFO - step: 000243 - done (%): 60.8 - loss: 0.811 - lr: 3.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.6 - avg_words_per_second: 3496.8 - ETA: >2025-09-23 04:55:28\n",
            "2025-09-23 04:06:44 (UTC) - 1:16:24 - train - INFO - step: 000244 - done (%): 61.0 - loss: 0.716 - lr: 3.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.8 - avg_words_per_second: 3497.3 - ETA: >2025-09-23 04:55:27\n",
            "2025-09-23 04:07:03 (UTC) - 1:16:43 - train - INFO - step: 000245 - done (%): 61.2 - loss: 0.708 - lr: 3.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3399.7 - avg_words_per_second: 3496.9 - ETA: >2025-09-23 04:55:28\n",
            "2025-09-23 04:07:21 (UTC) - 1:17:01 - train - INFO - step: 000246 - done (%): 61.5 - loss: 0.787 - lr: 3.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.4 - avg_words_per_second: 3497.4 - ETA: >2025-09-23 04:55:27\n",
            "2025-09-23 04:07:39 (UTC) - 1:17:20 - train - INFO - step: 000247 - done (%): 61.8 - loss: 0.745 - lr: 3.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.5 - avg_words_per_second: 3497.9 - ETA: >2025-09-23 04:55:26\n",
            "2025-09-23 04:07:59 (UTC) - 1:17:39 - train - INFO - step: 000248 - done (%): 62.0 - loss: 0.714 - lr: 3.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3395.0 - avg_words_per_second: 3497.4 - ETA: >2025-09-23 04:55:27\n",
            "2025-09-23 04:08:17 (UTC) - 1:17:57 - train - INFO - step: 000249 - done (%): 62.2 - loss: 0.738 - lr: 3.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.2 - avg_words_per_second: 3497.9 - ETA: >2025-09-23 04:55:26\n",
            "2025-09-23 04:08:35 (UTC) - 1:18:15 - train - INFO - step: 000250 - done (%): 62.5 - loss: 0.739 - lr: 3.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.7 - avg_words_per_second: 3498.4 - ETA: >2025-09-23 04:55:25\n",
            "2025-09-23 04:08:54 (UTC) - 1:18:34 - train - INFO - step: 000251 - done (%): 62.8 - loss: 0.757 - lr: 3.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3402.8 - avg_words_per_second: 3498.0 - ETA: >2025-09-23 04:55:26\n",
            "2025-09-23 04:09:12 (UTC) - 1:18:52 - train - INFO - step: 000252 - done (%): 63.0 - loss: 0.746 - lr: 3.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.4 - avg_words_per_second: 3498.5 - ETA: >2025-09-23 04:55:25\n",
            "2025-09-23 04:09:30 (UTC) - 1:19:10 - train - INFO - step: 000253 - done (%): 63.2 - loss: 0.758 - lr: 3.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.3 - avg_words_per_second: 3499.0 - ETA: >2025-09-23 04:55:24\n",
            "2025-09-23 04:09:49 (UTC) - 1:19:30 - train - INFO - step: 000254 - done (%): 63.5 - loss: 0.782 - lr: 3.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3396.8 - avg_words_per_second: 3498.6 - ETA: >2025-09-23 04:55:24\n",
            "2025-09-23 04:10:08 (UTC) - 1:19:48 - train - INFO - step: 000255 - done (%): 63.8 - loss: 0.845 - lr: 3.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.2 - avg_words_per_second: 3499.0 - ETA: >2025-09-23 04:55:23\n",
            "2025-09-23 04:10:26 (UTC) - 1:20:06 - train - INFO - step: 000256 - done (%): 64.0 - loss: 0.729 - lr: 3.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.2 - avg_words_per_second: 3499.5 - ETA: >2025-09-23 04:55:22\n",
            "2025-09-23 04:10:45 (UTC) - 1:20:25 - train - INFO - step: 000257 - done (%): 64.2 - loss: 0.669 - lr: 3.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3383.8 - avg_words_per_second: 3499.0 - ETA: >2025-09-23 04:55:23\n",
            "2025-09-23 04:11:03 (UTC) - 1:20:43 - train - INFO - step: 000258 - done (%): 64.5 - loss: 0.791 - lr: 3.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.3 - avg_words_per_second: 3499.5 - ETA: >2025-09-23 04:55:22\n",
            "2025-09-23 04:11:21 (UTC) - 1:21:02 - train - INFO - step: 000259 - done (%): 64.8 - loss: 0.779 - lr: 3.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.8 - avg_words_per_second: 3499.9 - ETA: >2025-09-23 04:55:21\n",
            "2025-09-23 04:11:41 (UTC) - 1:21:21 - train - INFO - step: 000260 - done (%): 65.0 - loss: 0.787 - lr: 3.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3398.7 - avg_words_per_second: 3499.5 - ETA: >2025-09-23 04:55:22\n",
            "2025-09-23 04:11:59 (UTC) - 1:21:39 - train - INFO - step: 000261 - done (%): 65.2 - loss: 0.773 - lr: 3.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.6 - avg_words_per_second: 3500.0 - ETA: >2025-09-23 04:55:21\n",
            "2025-09-23 04:12:17 (UTC) - 1:21:57 - train - INFO - step: 000262 - done (%): 65.5 - loss: 0.768 - lr: 2.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3500.5 - ETA: >2025-09-23 04:55:20\n",
            "2025-09-23 04:12:36 (UTC) - 1:22:16 - train - INFO - step: 000263 - done (%): 65.8 - loss: 0.817 - lr: 2.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3388.4 - avg_words_per_second: 3500.0 - ETA: >2025-09-23 04:55:21\n",
            "2025-09-23 04:12:54 (UTC) - 1:22:34 - train - INFO - step: 000264 - done (%): 66.0 - loss: 0.728 - lr: 2.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.2 - avg_words_per_second: 3500.5 - ETA: >2025-09-23 04:55:20\n",
            "2025-09-23 04:13:12 (UTC) - 1:22:52 - train - INFO - step: 000265 - done (%): 66.2 - loss: 0.791 - lr: 2.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.0 - avg_words_per_second: 3500.9 - ETA: >2025-09-23 04:55:19\n",
            "2025-09-23 04:13:32 (UTC) - 1:23:12 - train - INFO - step: 000266 - done (%): 66.5 - loss: 0.871 - lr: 2.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3353.1 - avg_words_per_second: 3500.3 - ETA: >2025-09-23 04:55:21\n",
            "2025-09-23 04:13:50 (UTC) - 1:23:30 - train - INFO - step: 000267 - done (%): 66.8 - loss: 0.771 - lr: 2.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3616.1 - avg_words_per_second: 3500.8 - ETA: >2025-09-23 04:55:20\n",
            "2025-09-23 04:14:08 (UTC) - 1:23:48 - train - INFO - step: 000268 - done (%): 67.0 - loss: 0.801 - lr: 2.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.2 - avg_words_per_second: 3501.2 - ETA: >2025-09-23 04:55:19\n",
            "2025-09-23 04:14:27 (UTC) - 1:24:08 - train - INFO - step: 000269 - done (%): 67.2 - loss: 0.673 - lr: 2.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3390.6 - avg_words_per_second: 3500.8 - ETA: >2025-09-23 04:55:20\n",
            "2025-09-23 04:14:45 (UTC) - 1:24:26 - train - INFO - step: 000270 - done (%): 67.5 - loss: 0.733 - lr: 2.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.2 - avg_words_per_second: 3501.3 - ETA: >2025-09-23 04:55:19\n",
            "2025-09-23 04:15:03 (UTC) - 1:24:44 - train - INFO - step: 000271 - done (%): 67.8 - loss: 0.741 - lr: 2.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.0 - avg_words_per_second: 3501.7 - ETA: >2025-09-23 04:55:18\n",
            "2025-09-23 04:15:23 (UTC) - 1:25:03 - train - INFO - step: 000272 - done (%): 68.0 - loss: 0.800 - lr: 2.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3397.0 - avg_words_per_second: 3501.3 - ETA: >2025-09-23 04:55:19\n",
            "2025-09-23 04:15:41 (UTC) - 1:25:21 - train - INFO - step: 000273 - done (%): 68.2 - loss: 0.772 - lr: 2.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.7 - avg_words_per_second: 3501.7 - ETA: >2025-09-23 04:55:18\n",
            "2025-09-23 04:15:59 (UTC) - 1:25:39 - train - INFO - step: 000274 - done (%): 68.5 - loss: 0.741 - lr: 2.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.2 - avg_words_per_second: 3502.1 - ETA: >2025-09-23 04:55:17\n",
            "2025-09-23 04:16:17 (UTC) - 1:25:57 - train - INFO - step: 000275 - done (%): 68.8 - loss: 0.814 - lr: 2.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.6 - avg_words_per_second: 3502.6 - ETA: >2025-09-23 04:55:16\n",
            "2025-09-23 04:16:36 (UTC) - 1:26:17 - train - INFO - step: 000276 - done (%): 69.0 - loss: 0.725 - lr: 2.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3372.1 - avg_words_per_second: 3502.1 - ETA: >2025-09-23 04:55:17\n",
            "2025-09-23 04:16:55 (UTC) - 1:26:35 - train - INFO - step: 000277 - done (%): 69.2 - loss: 0.772 - lr: 2.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.0 - avg_words_per_second: 3502.5 - ETA: >2025-09-23 04:55:16\n",
            "2025-09-23 04:17:13 (UTC) - 1:26:53 - train - INFO - step: 000278 - done (%): 69.5 - loss: 0.771 - lr: 2.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.7 - avg_words_per_second: 3502.9 - ETA: >2025-09-23 04:55:15\n",
            "2025-09-23 04:17:32 (UTC) - 1:27:12 - train - INFO - step: 000279 - done (%): 69.8 - loss: 0.790 - lr: 2.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3365.9 - avg_words_per_second: 3502.4 - ETA: >2025-09-23 04:55:16\n",
            "2025-09-23 04:17:50 (UTC) - 1:27:30 - train - INFO - step: 000280 - done (%): 70.0 - loss: 0.807 - lr: 2.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.7 - avg_words_per_second: 3502.8 - ETA: >2025-09-23 04:55:15\n",
            "2025-09-23 04:18:08 (UTC) - 1:27:49 - train - INFO - step: 000281 - done (%): 70.2 - loss: 0.765 - lr: 2.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.6 - avg_words_per_second: 3503.2 - ETA: >2025-09-23 04:55:14\n",
            "2025-09-23 04:18:28 (UTC) - 1:28:08 - train - INFO - step: 000282 - done (%): 70.5 - loss: 0.859 - lr: 2.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3358.7 - avg_words_per_second: 3502.7 - ETA: >2025-09-23 04:55:16\n",
            "2025-09-23 04:18:46 (UTC) - 1:28:26 - train - INFO - step: 000283 - done (%): 70.8 - loss: 0.705 - lr: 2.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.4 - avg_words_per_second: 3503.1 - ETA: >2025-09-23 04:55:15\n",
            "2025-09-23 04:19:04 (UTC) - 1:28:44 - train - INFO - step: 000284 - done (%): 71.0 - loss: 0.787 - lr: 2.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.5 - avg_words_per_second: 3503.5 - ETA: >2025-09-23 04:55:14\n",
            "2025-09-23 04:19:23 (UTC) - 1:29:04 - train - INFO - step: 000285 - done (%): 71.2 - loss: 0.736 - lr: 2.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3376.3 - avg_words_per_second: 3503.0 - ETA: >2025-09-23 04:55:15\n",
            "2025-09-23 04:19:42 (UTC) - 1:29:22 - train - INFO - step: 000286 - done (%): 71.5 - loss: 0.700 - lr: 2.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.7 - avg_words_per_second: 3503.4 - ETA: >2025-09-23 04:55:14\n",
            "2025-09-23 04:20:00 (UTC) - 1:29:40 - train - INFO - step: 000287 - done (%): 71.8 - loss: 0.747 - lr: 2.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.3 - avg_words_per_second: 3503.8 - ETA: >2025-09-23 04:55:13\n",
            "2025-09-23 04:20:19 (UTC) - 1:29:59 - train - INFO - step: 000288 - done (%): 72.0 - loss: 0.807 - lr: 2.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3361.2 - avg_words_per_second: 3503.3 - ETA: >2025-09-23 04:55:14\n",
            "2025-09-23 04:20:37 (UTC) - 1:30:17 - train - INFO - step: 000289 - done (%): 72.2 - loss: 0.745 - lr: 2.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.4 - avg_words_per_second: 3503.7 - ETA: >2025-09-23 04:55:13\n",
            "2025-09-23 04:20:55 (UTC) - 1:30:36 - train - INFO - step: 000290 - done (%): 72.5 - loss: 0.699 - lr: 1.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.4 - avg_words_per_second: 3504.1 - ETA: >2025-09-23 04:55:13\n",
            "2025-09-23 04:21:15 (UTC) - 1:30:55 - train - INFO - step: 000291 - done (%): 72.8 - loss: 0.742 - lr: 1.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3386.8 - avg_words_per_second: 3503.7 - ETA: >2025-09-23 04:55:13\n",
            "2025-09-23 04:21:33 (UTC) - 1:31:13 - train - INFO - step: 000292 - done (%): 73.0 - loss: 0.743 - lr: 1.9e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.1 - avg_words_per_second: 3504.1 - ETA: >2025-09-23 04:55:13\n",
            "2025-09-23 04:21:51 (UTC) - 1:31:31 - train - INFO - step: 000293 - done (%): 73.2 - loss: 0.754 - lr: 1.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.7 - avg_words_per_second: 3504.5 - ETA: >2025-09-23 04:55:12\n",
            "2025-09-23 04:22:10 (UTC) - 1:31:50 - train - INFO - step: 000294 - done (%): 73.5 - loss: 0.734 - lr: 1.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3374.5 - avg_words_per_second: 3504.0 - ETA: >2025-09-23 04:55:13\n",
            "2025-09-23 04:22:28 (UTC) - 1:32:09 - train - INFO - step: 000295 - done (%): 73.8 - loss: 0.797 - lr: 1.8e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.1 - avg_words_per_second: 3504.4 - ETA: >2025-09-23 04:55:12\n",
            "2025-09-23 04:22:46 (UTC) - 1:32:27 - train - INFO - step: 000296 - done (%): 74.0 - loss: 0.693 - lr: 1.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.9 - avg_words_per_second: 3504.8 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:23:06 (UTC) - 1:32:46 - train - INFO - step: 000297 - done (%): 74.2 - loss: 0.775 - lr: 1.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3398.7 - avg_words_per_second: 3504.4 - ETA: >2025-09-23 04:55:12\n",
            "2025-09-23 04:23:24 (UTC) - 1:33:04 - train - INFO - step: 000298 - done (%): 74.5 - loss: 0.833 - lr: 1.7e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.9 - avg_words_per_second: 3504.8 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:23:42 (UTC) - 1:33:22 - train - INFO - step: 000299 - done (%): 74.8 - loss: 0.736 - lr: 1.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.9 - avg_words_per_second: 3505.2 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:24:01 (UTC) - 1:33:41 - train - INFO - step: 000300 - done (%): 75.0 - loss: 0.758 - lr: 1.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3393.5 - avg_words_per_second: 3504.8 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:24:01 (UTC) - 1:33:41 - checkpointing - INFO - Dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000300/consolidated using tmp name: tmp.consolidated\n",
            "2025-09-23 04:24:02 (UTC) - 1:33:43 - checkpointing - INFO - Done dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000300/consolidated for step: 300\n",
            "2025-09-23 04:24:02 (UTC) - 1:33:43 - checkpointing - INFO - Done deleting checkpoints \n",
            "2025-09-23 04:24:02 (UTC) - 1:33:43 - checkpointing - INFO - Done!\n",
            "2025-09-23 04:24:20 (UTC) - 1:34:01 - train - INFO - step: 000301 - done (%): 75.2 - loss: 0.821 - lr: 1.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.5 - avg_words_per_second: 3505.2 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:24:39 (UTC) - 1:34:19 - train - INFO - step: 000302 - done (%): 75.5 - loss: 0.724 - lr: 1.6e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3609.0 - avg_words_per_second: 3505.5 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:24:58 (UTC) - 1:34:38 - train - INFO - step: 000303 - done (%): 75.8 - loss: 0.776 - lr: 1.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3372.2 - avg_words_per_second: 3505.1 - ETA: >2025-09-23 04:55:12\n",
            "2025-09-23 04:25:16 (UTC) - 1:34:56 - train - INFO - step: 000304 - done (%): 76.0 - loss: 0.760 - lr: 1.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.1 - avg_words_per_second: 3505.5 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:25:34 (UTC) - 1:35:14 - train - INFO - step: 000305 - done (%): 76.2 - loss: 0.718 - lr: 1.5e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.5 - avg_words_per_second: 3505.8 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:25:54 (UTC) - 1:35:34 - train - INFO - step: 000306 - done (%): 76.5 - loss: 0.728 - lr: 1.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3350.6 - avg_words_per_second: 3505.3 - ETA: >2025-09-23 04:55:11\n",
            "2025-09-23 04:26:12 (UTC) - 1:35:52 - train - INFO - step: 000307 - done (%): 76.8 - loss: 0.797 - lr: 1.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3631.6 - avg_words_per_second: 3505.7 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:26:30 (UTC) - 1:36:10 - train - INFO - step: 000308 - done (%): 77.0 - loss: 0.772 - lr: 1.4e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3616.3 - avg_words_per_second: 3506.0 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:26:49 (UTC) - 1:36:30 - train - INFO - step: 000309 - done (%): 77.2 - loss: 0.795 - lr: 1.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3390.6 - avg_words_per_second: 3505.7 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:27:07 (UTC) - 1:36:48 - train - INFO - step: 000310 - done (%): 77.5 - loss: 0.764 - lr: 1.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.4 - avg_words_per_second: 3506.0 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:27:25 (UTC) - 1:37:06 - train - INFO - step: 000311 - done (%): 77.8 - loss: 0.739 - lr: 1.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.1 - avg_words_per_second: 3506.4 - ETA: >2025-09-23 04:55:09\n",
            "2025-09-23 04:27:45 (UTC) - 1:37:25 - train - INFO - step: 000312 - done (%): 78.0 - loss: 0.821 - lr: 1.3e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3381.2 - avg_words_per_second: 3506.0 - ETA: >2025-09-23 04:55:10\n",
            "2025-09-23 04:28:03 (UTC) - 1:37:43 - train - INFO - step: 000313 - done (%): 78.2 - loss: 0.795 - lr: 1.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.7 - avg_words_per_second: 3506.3 - ETA: >2025-09-23 04:55:09\n",
            "2025-09-23 04:28:21 (UTC) - 1:38:01 - train - INFO - step: 000314 - done (%): 78.5 - loss: 0.742 - lr: 1.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.6 - avg_words_per_second: 3506.7 - ETA: >2025-09-23 04:55:08\n",
            "2025-09-23 04:28:31 (UTC) - 1:38:12 - dataset - INFO - Shuffling /content/data/ct-training.jsonl ...\n",
            "2025-09-23 04:28:41 (UTC) - 1:38:21 - train - INFO - step: 000315 - done (%): 78.8 - loss: 0.661 - lr: 1.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3364.4 - avg_words_per_second: 3506.2 - ETA: >2025-09-23 04:55:09\n",
            "2025-09-23 04:28:59 (UTC) - 1:38:39 - train - INFO - step: 000316 - done (%): 79.0 - loss: 0.659 - lr: 1.2e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.5 - avg_words_per_second: 3506.6 - ETA: >2025-09-23 04:55:08\n",
            "2025-09-23 04:29:17 (UTC) - 1:38:57 - train - INFO - step: 000317 - done (%): 79.2 - loss: 0.611 - lr: 1.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.1 - avg_words_per_second: 3506.9 - ETA: >2025-09-23 04:55:08\n",
            "2025-09-23 04:29:36 (UTC) - 1:39:16 - train - INFO - step: 000318 - done (%): 79.5 - loss: 0.589 - lr: 1.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3386.8 - avg_words_per_second: 3506.5 - ETA: >2025-09-23 04:55:09\n",
            "2025-09-23 04:29:54 (UTC) - 1:39:34 - train - INFO - step: 000319 - done (%): 79.8 - loss: 0.621 - lr: 1.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.0 - avg_words_per_second: 3506.9 - ETA: >2025-09-23 04:55:08\n",
            "2025-09-23 04:30:12 (UTC) - 1:39:53 - train - INFO - step: 000320 - done (%): 80.0 - loss: 0.568 - lr: 1.1e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.5 - avg_words_per_second: 3507.2 - ETA: >2025-09-23 04:55:07\n",
            "2025-09-23 04:30:32 (UTC) - 1:40:12 - train - INFO - step: 000321 - done (%): 80.2 - loss: 0.597 - lr: 1.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3391.2 - avg_words_per_second: 3506.8 - ETA: >2025-09-23 04:55:08\n",
            "2025-09-23 04:30:50 (UTC) - 1:40:30 - train - INFO - step: 000322 - done (%): 80.5 - loss: 0.560 - lr: 1.0e-05 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.2 - avg_words_per_second: 3507.2 - ETA: >2025-09-23 04:55:07\n",
            "2025-09-23 04:31:08 (UTC) - 1:40:48 - train - INFO - step: 000323 - done (%): 80.8 - loss: 0.672 - lr: 9.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.3 - avg_words_per_second: 3507.5 - ETA: >2025-09-23 04:55:06\n",
            "2025-09-23 04:31:27 (UTC) - 1:41:07 - train - INFO - step: 000324 - done (%): 81.0 - loss: 0.585 - lr: 9.5e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3385.4 - avg_words_per_second: 3507.1 - ETA: >2025-09-23 04:55:07\n",
            "2025-09-23 04:31:45 (UTC) - 1:41:25 - train - INFO - step: 000325 - done (%): 81.2 - loss: 0.573 - lr: 9.3e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.7 - avg_words_per_second: 3507.5 - ETA: >2025-09-23 04:55:07\n",
            "2025-09-23 04:32:03 (UTC) - 1:41:44 - train - INFO - step: 000326 - done (%): 81.5 - loss: 0.620 - lr: 9.1e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3619.6 - avg_words_per_second: 3507.8 - ETA: >2025-09-23 04:55:06\n",
            "2025-09-23 04:32:23 (UTC) - 1:42:03 - train - INFO - step: 000327 - done (%): 81.8 - loss: 0.631 - lr: 8.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3370.4 - avg_words_per_second: 3507.4 - ETA: >2025-09-23 04:55:07\n",
            "2025-09-23 04:32:41 (UTC) - 1:42:21 - train - INFO - step: 000328 - done (%): 82.0 - loss: 0.615 - lr: 8.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.8 - avg_words_per_second: 3507.7 - ETA: >2025-09-23 04:55:06\n",
            "2025-09-23 04:32:59 (UTC) - 1:42:39 - train - INFO - step: 000329 - done (%): 82.2 - loss: 0.583 - lr: 8.4e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.8 - avg_words_per_second: 3508.1 - ETA: >2025-09-23 04:55:05\n",
            "2025-09-23 04:33:18 (UTC) - 1:42:58 - train - INFO - step: 000330 - done (%): 82.5 - loss: 0.628 - lr: 8.1e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3395.2 - avg_words_per_second: 3507.7 - ETA: >2025-09-23 04:55:06\n",
            "2025-09-23 04:33:36 (UTC) - 1:43:17 - train - INFO - step: 000331 - done (%): 82.8 - loss: 0.620 - lr: 7.9e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.3 - avg_words_per_second: 3508.1 - ETA: >2025-09-23 04:55:05\n",
            "2025-09-23 04:33:54 (UTC) - 1:43:35 - train - INFO - step: 000332 - done (%): 83.0 - loss: 0.627 - lr: 7.7e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.5 - avg_words_per_second: 3508.4 - ETA: >2025-09-23 04:55:05\n",
            "2025-09-23 04:34:14 (UTC) - 1:43:54 - train - INFO - step: 000333 - done (%): 83.2 - loss: 0.596 - lr: 7.5e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.8 - avg_words_per_second: 3508.0 - ETA: >2025-09-23 04:55:05\n",
            "2025-09-23 04:34:32 (UTC) - 1:44:12 - train - INFO - step: 000334 - done (%): 83.5 - loss: 0.591 - lr: 7.3e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.5 - avg_words_per_second: 3508.4 - ETA: >2025-09-23 04:55:05\n",
            "2025-09-23 04:34:50 (UTC) - 1:44:30 - train - INFO - step: 000335 - done (%): 83.8 - loss: 0.609 - lr: 7.0e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3610.8 - avg_words_per_second: 3508.7 - ETA: >2025-09-23 04:55:04\n",
            "2025-09-23 04:35:09 (UTC) - 1:44:50 - train - INFO - step: 000336 - done (%): 84.0 - loss: 0.636 - lr: 6.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3382.6 - avg_words_per_second: 3508.3 - ETA: >2025-09-23 04:55:05\n",
            "2025-09-23 04:35:27 (UTC) - 1:45:08 - train - INFO - step: 000337 - done (%): 84.2 - loss: 0.623 - lr: 6.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.9 - avg_words_per_second: 3508.6 - ETA: >2025-09-23 04:55:04\n",
            "2025-09-23 04:35:45 (UTC) - 1:45:26 - train - INFO - step: 000338 - done (%): 84.5 - loss: 0.609 - lr: 6.4e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3628.0 - avg_words_per_second: 3508.9 - ETA: >2025-09-23 04:55:03\n",
            "2025-09-23 04:36:05 (UTC) - 1:45:45 - train - INFO - step: 000339 - done (%): 84.8 - loss: 0.611 - lr: 6.2e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3373.9 - avg_words_per_second: 3508.5 - ETA: >2025-09-23 04:55:04\n",
            "2025-09-23 04:36:23 (UTC) - 1:46:03 - train - INFO - step: 000340 - done (%): 85.0 - loss: 0.653 - lr: 6.0e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.8 - avg_words_per_second: 3508.9 - ETA: >2025-09-23 04:55:04\n",
            "2025-09-23 04:36:41 (UTC) - 1:46:21 - train - INFO - step: 000341 - done (%): 85.2 - loss: 0.626 - lr: 5.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.6 - avg_words_per_second: 3509.2 - ETA: >2025-09-23 04:55:03\n",
            "2025-09-23 04:37:00 (UTC) - 1:46:41 - train - INFO - step: 000342 - done (%): 85.5 - loss: 0.631 - lr: 5.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3397.6 - avg_words_per_second: 3508.9 - ETA: >2025-09-23 04:55:04\n",
            "2025-09-23 04:37:18 (UTC) - 1:46:59 - train - INFO - step: 000343 - done (%): 85.8 - loss: 0.605 - lr: 5.5e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.4 - avg_words_per_second: 3509.2 - ETA: >2025-09-23 04:55:03\n",
            "2025-09-23 04:37:37 (UTC) - 1:47:17 - train - INFO - step: 000344 - done (%): 86.0 - loss: 0.582 - lr: 5.3e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3614.2 - avg_words_per_second: 3509.5 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:37:56 (UTC) - 1:47:36 - train - INFO - step: 000345 - done (%): 86.2 - loss: 0.664 - lr: 5.1e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3392.7 - avg_words_per_second: 3509.1 - ETA: >2025-09-23 04:55:03\n",
            "2025-09-23 04:38:14 (UTC) - 1:47:54 - train - INFO - step: 000346 - done (%): 86.5 - loss: 0.593 - lr: 4.9e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.8 - avg_words_per_second: 3509.4 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:38:32 (UTC) - 1:48:12 - train - INFO - step: 000347 - done (%): 86.8 - loss: 0.564 - lr: 4.7e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.1 - avg_words_per_second: 3509.7 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:38:52 (UTC) - 1:48:32 - train - INFO - step: 000348 - done (%): 87.0 - loss: 0.615 - lr: 4.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3374.5 - avg_words_per_second: 3509.3 - ETA: >2025-09-23 04:55:03\n",
            "2025-09-23 04:39:10 (UTC) - 1:48:50 - train - INFO - step: 000349 - done (%): 87.2 - loss: 0.659 - lr: 4.4e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.3 - avg_words_per_second: 3509.7 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:39:28 (UTC) - 1:49:08 - train - INFO - step: 000350 - done (%): 87.5 - loss: 0.620 - lr: 4.2e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3618.4 - avg_words_per_second: 3510.0 - ETA: >2025-09-23 04:55:01\n",
            "2025-09-23 04:39:47 (UTC) - 1:49:27 - train - INFO - step: 000351 - done (%): 87.8 - loss: 0.594 - lr: 4.0e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3374.0 - avg_words_per_second: 3509.6 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:40:05 (UTC) - 1:49:46 - train - INFO - step: 000352 - done (%): 88.0 - loss: 0.594 - lr: 3.9e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.3 - avg_words_per_second: 3509.9 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:40:23 (UTC) - 1:50:04 - train - INFO - step: 000353 - done (%): 88.2 - loss: 0.629 - lr: 3.7e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.1 - avg_words_per_second: 3510.2 - ETA: >2025-09-23 04:55:01\n",
            "2025-09-23 04:40:43 (UTC) - 1:50:23 - train - INFO - step: 000354 - done (%): 88.5 - loss: 0.603 - lr: 3.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3397.4 - avg_words_per_second: 3509.8 - ETA: >2025-09-23 04:55:02\n",
            "2025-09-23 04:41:01 (UTC) - 1:50:41 - train - INFO - step: 000355 - done (%): 88.8 - loss: 0.576 - lr: 3.4e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.5 - avg_words_per_second: 3510.2 - ETA: >2025-09-23 04:55:01\n",
            "2025-09-23 04:41:19 (UTC) - 1:50:59 - train - INFO - step: 000356 - done (%): 89.0 - loss: 0.634 - lr: 3.3e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.6 - avg_words_per_second: 3510.5 - ETA: >2025-09-23 04:55:00\n",
            "2025-09-23 04:41:38 (UTC) - 1:51:18 - train - INFO - step: 000357 - done (%): 89.2 - loss: 0.613 - lr: 3.1e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3385.4 - avg_words_per_second: 3510.1 - ETA: >2025-09-23 04:55:01\n",
            "2025-09-23 04:41:56 (UTC) - 1:51:37 - train - INFO - step: 000358 - done (%): 89.5 - loss: 0.605 - lr: 3.0e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.3 - avg_words_per_second: 3510.4 - ETA: >2025-09-23 04:55:00\n",
            "2025-09-23 04:42:14 (UTC) - 1:51:55 - train - INFO - step: 000359 - done (%): 89.8 - loss: 0.636 - lr: 2.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.0 - avg_words_per_second: 3510.7 - ETA: >2025-09-23 04:55:00\n",
            "2025-09-23 04:42:34 (UTC) - 1:52:14 - train - INFO - step: 000360 - done (%): 90.0 - loss: 0.569 - lr: 2.7e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3378.9 - avg_words_per_second: 3510.4 - ETA: >2025-09-23 04:55:00\n",
            "2025-09-23 04:42:52 (UTC) - 1:52:32 - train - INFO - step: 000361 - done (%): 90.2 - loss: 0.581 - lr: 2.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.5 - avg_words_per_second: 3510.7 - ETA: >2025-09-23 04:55:00\n",
            "2025-09-23 04:43:10 (UTC) - 1:52:50 - train - INFO - step: 000362 - done (%): 90.5 - loss: 0.608 - lr: 2.4e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.7 - avg_words_per_second: 3511.0 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:43:29 (UTC) - 1:53:10 - train - INFO - step: 000363 - done (%): 90.8 - loss: 0.639 - lr: 2.3e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3375.5 - avg_words_per_second: 3510.6 - ETA: >2025-09-23 04:55:00\n",
            "2025-09-23 04:43:47 (UTC) - 1:53:28 - train - INFO - step: 000364 - done (%): 91.0 - loss: 0.614 - lr: 2.2e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.2 - avg_words_per_second: 3510.9 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:44:05 (UTC) - 1:53:46 - train - INFO - step: 000365 - done (%): 91.2 - loss: 0.590 - lr: 2.1e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.2 - avg_words_per_second: 3511.2 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:44:25 (UTC) - 1:54:05 - train - INFO - step: 000366 - done (%): 91.5 - loss: 0.580 - lr: 2.0e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3392.1 - avg_words_per_second: 3510.8 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:44:43 (UTC) - 1:54:23 - train - INFO - step: 000367 - done (%): 91.8 - loss: 0.611 - lr: 1.8e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.1 - avg_words_per_second: 3511.1 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:45:01 (UTC) - 1:54:41 - train - INFO - step: 000368 - done (%): 92.0 - loss: 0.665 - lr: 1.7e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.9 - avg_words_per_second: 3511.4 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:45:20 (UTC) - 1:55:01 - train - INFO - step: 000369 - done (%): 92.2 - loss: 0.579 - lr: 1.6e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3379.1 - avg_words_per_second: 3511.0 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:45:38 (UTC) - 1:55:19 - train - INFO - step: 000370 - done (%): 92.5 - loss: 0.646 - lr: 1.5e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3630.6 - avg_words_per_second: 3511.3 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:45:57 (UTC) - 1:55:37 - train - INFO - step: 000371 - done (%): 92.8 - loss: 0.611 - lr: 1.4e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.8 - avg_words_per_second: 3511.7 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:46:16 (UTC) - 1:55:56 - train - INFO - step: 000372 - done (%): 93.0 - loss: 0.633 - lr: 1.3e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3382.8 - avg_words_per_second: 3511.3 - ETA: >2025-09-23 04:54:59\n",
            "2025-09-23 04:46:34 (UTC) - 1:56:14 - train - INFO - step: 000373 - done (%): 93.2 - loss: 0.659 - lr: 1.2e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.3 - avg_words_per_second: 3511.6 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:46:52 (UTC) - 1:56:32 - train - INFO - step: 000374 - done (%): 93.5 - loss: 0.643 - lr: 1.2e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3617.0 - avg_words_per_second: 3511.9 - ETA: >2025-09-23 04:54:57\n",
            "2025-09-23 04:47:12 (UTC) - 1:56:52 - train - INFO - step: 000375 - done (%): 93.8 - loss: 0.602 - lr: 1.1e-06 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3367.0 - avg_words_per_second: 3511.5 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:47:30 (UTC) - 1:57:10 - train - INFO - step: 000376 - done (%): 94.0 - loss: 0.579 - lr: 9.8e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3614.7 - avg_words_per_second: 3511.7 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:47:48 (UTC) - 1:57:28 - train - INFO - step: 000377 - done (%): 94.2 - loss: 0.601 - lr: 9.0e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.7 - avg_words_per_second: 3512.0 - ETA: >2025-09-23 04:54:57\n",
            "2025-09-23 04:48:07 (UTC) - 1:57:47 - train - INFO - step: 000378 - done (%): 94.5 - loss: 0.580 - lr: 8.3e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3392.0 - avg_words_per_second: 3511.7 - ETA: >2025-09-23 04:54:58\n",
            "2025-09-23 04:48:25 (UTC) - 1:58:05 - train - INFO - step: 000379 - done (%): 94.8 - loss: 0.602 - lr: 7.5e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.1 - avg_words_per_second: 3512.0 - ETA: >2025-09-23 04:54:57\n",
            "2025-09-23 04:48:43 (UTC) - 1:58:24 - train - INFO - step: 000380 - done (%): 95.0 - loss: 0.569 - lr: 6.8e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.6 - avg_words_per_second: 3512.3 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:49:03 (UTC) - 1:58:43 - train - INFO - step: 000381 - done (%): 95.2 - loss: 0.593 - lr: 6.2e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3387.2 - avg_words_per_second: 3511.9 - ETA: >2025-09-23 04:54:57\n",
            "2025-09-23 04:49:21 (UTC) - 1:59:01 - train - INFO - step: 000382 - done (%): 95.5 - loss: 0.625 - lr: 5.5e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3627.1 - avg_words_per_second: 3512.2 - ETA: >2025-09-23 04:54:57\n",
            "2025-09-23 04:49:39 (UTC) - 1:59:19 - train - INFO - step: 000383 - done (%): 95.8 - loss: 0.585 - lr: 4.9e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.7 - avg_words_per_second: 3512.5 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:49:58 (UTC) - 1:59:38 - train - INFO - step: 000384 - done (%): 96.0 - loss: 0.605 - lr: 4.4e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3384.3 - avg_words_per_second: 3512.1 - ETA: >2025-09-23 04:54:57\n",
            "2025-09-23 04:50:16 (UTC) - 1:59:56 - train - INFO - step: 000385 - done (%): 96.2 - loss: 0.607 - lr: 3.8e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.7 - avg_words_per_second: 3512.4 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:50:34 (UTC) - 2:00:15 - train - INFO - step: 000386 - done (%): 96.5 - loss: 0.547 - lr: 3.3e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3615.9 - avg_words_per_second: 3512.7 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:50:54 (UTC) - 2:00:34 - train - INFO - step: 000387 - done (%): 96.8 - loss: 0.621 - lr: 2.9e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3360.1 - avg_words_per_second: 3512.3 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:51:12 (UTC) - 2:00:52 - train - INFO - step: 000388 - done (%): 97.0 - loss: 0.580 - lr: 2.5e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.6 - avg_words_per_second: 3512.6 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:51:30 (UTC) - 2:01:10 - train - INFO - step: 000389 - done (%): 97.2 - loss: 0.669 - lr: 2.1e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3629.8 - avg_words_per_second: 3512.8 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:51:49 (UTC) - 2:01:30 - train - INFO - step: 000390 - done (%): 97.5 - loss: 0.622 - lr: 1.7e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3398.6 - avg_words_per_second: 3512.5 - ETA: >2025-09-23 04:54:56\n",
            "2025-09-23 04:52:07 (UTC) - 2:01:48 - train - INFO - step: 000391 - done (%): 97.8 - loss: 0.650 - lr: 1.4e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3626.4 - avg_words_per_second: 3512.8 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:52:25 (UTC) - 2:02:06 - train - INFO - step: 000392 - done (%): 98.0 - loss: 0.611 - lr: 1.1e-07 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3624.4 - avg_words_per_second: 3513.1 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:52:45 (UTC) - 2:02:25 - train - INFO - step: 000393 - done (%): 98.2 - loss: 0.653 - lr: 8.4e-08 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3384.2 - avg_words_per_second: 3512.8 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:53:03 (UTC) - 2:02:43 - train - INFO - step: 000394 - done (%): 98.5 - loss: 0.625 - lr: 6.2e-08 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3622.0 - avg_words_per_second: 3513.0 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:53:21 (UTC) - 2:03:01 - train - INFO - step: 000395 - done (%): 98.8 - loss: 0.565 - lr: 4.3e-08 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3623.6 - avg_words_per_second: 3513.3 - ETA: >2025-09-23 04:54:54\n",
            "2025-09-23 04:53:40 (UTC) - 2:03:21 - train - INFO - step: 000396 - done (%): 99.0 - loss: 0.606 - lr: 2.8e-08 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3380.9 - avg_words_per_second: 3513.0 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:53:58 (UTC) - 2:03:39 - train - INFO - step: 000397 - done (%): 99.2 - loss: 0.549 - lr: 1.6e-08 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3625.5 - avg_words_per_second: 3513.2 - ETA: >2025-09-23 04:54:54\n",
            "2025-09-23 04:54:17 (UTC) - 2:03:57 - train - INFO - step: 000398 - done (%): 99.5 - loss: 0.611 - lr: 7.2e-09 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3620.6 - avg_words_per_second: 3513.5 - ETA: >2025-09-23 04:54:54\n",
            "2025-09-23 04:54:36 (UTC) - 2:04:16 - train - INFO - step: 000399 - done (%): 99.8 - loss: 0.590 - lr: 2.1e-09 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3369.9 - avg_words_per_second: 3513.1 - ETA: >2025-09-23 04:54:55\n",
            "2025-09-23 04:54:54 (UTC) - 2:04:34 - train - INFO - step: 000400 - done (%): 100.0 - loss: 0.595 - lr: 4.0e-10 - peak_alloc_mem (GB): 24.1 - alloc_mem (GB): 19.0 - words_per_second: 3621.2 - avg_words_per_second: 3513.4 - ETA: >2025-09-23 04:54:54\n",
            "2025-09-23 04:54:54 (UTC) - 2:04:34 - checkpointing - INFO - Dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000400/consolidated using tmp name: tmp.consolidated\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - checkpointing - INFO - Done dumping checkpoint in /content/test_ultra/checkpoints/checkpoint_000400/consolidated for step: 400\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - checkpointing - INFO - Deleted ckpt: /content/test_ultra/checkpoints/checkpoint_000100\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - checkpointing - INFO - Done deleting checkpoints /content/test_ultra/checkpoints/checkpoint_000100\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - checkpointing - INFO - Done!\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - train - INFO - done!\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - utils - INFO - Closing: eval_logger\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - utils - INFO - Closed: eval_logger\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - utils - INFO - Closing: metrics_logger\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - utils - INFO - Closed: metrics_logger\n",
            "2025-09-23 04:54:55 (UTC) - 2:04:36 - train - INFO - Closed everything!\n"
          ]
        }
      ],
      "source": [
        "# start training\n",
        "!conda run --live-stream -n myenv torchrun --nproc-per-node 1 -m train example.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruJ29JFn98zE"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7BWNGKt9-Kxz",
        "outputId": "63503f2d-9a76-478c-89e7-1a46304de87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral_inference\n",
            "  Downloading mistral_inference-1.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting fire>=0.6.0 (from mistral_inference)\n",
            "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting mistral_common>=1.5.4 (from mistral_inference)\n",
            "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pillow>=10.3.0 (from mistral_inference)\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting safetensors>=0.4.0 (from mistral_inference)\n",
            "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting simple-parsing>=0.1.5 (from mistral_inference)\n",
            "  Using cached simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting xformers>=0.0.24 (from mistral_inference)\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting termcolor (from fire>=0.6.0->mistral_inference)\n",
            "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pydantic<3.0,>=2.7 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting jsonschema>=4.21.1 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.11.0 in /usr/local/lib/python3.11/site-packages (from mistral_common>=1.5.4->mistral_inference) (4.15.0)\n",
            "Collecting tiktoken>=0.7.0 (from mistral_common>=1.5.4->mistral_inference)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/34/9a/db7a86b829e05a01fd4daa492086f708e0a8b53952e1dbc9d380d2b03677/tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/site-packages (from mistral_common>=1.5.4->mistral_inference) (2.32.3)\n",
            "Collecting numpy>=1.25 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pydantic_extra_types-2.10.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting docstring-parser<1.0,>=0.15 (from simple-parsing>=0.1.5->mistral_inference)\n",
            "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting torch==2.8.0 (from xformers>=0.0.24->mistral_inference)\n",
            "  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch==2.8.0->xformers>=0.0.24->mistral_inference) (3.19.1)\n",
            "Collecting sympy>=1.13.3 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch==2.8.0->xformers>=0.0.24->mistral_inference) (2025.9.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch==2.8.0->xformers>=0.0.24->mistral_inference) (65.6.3)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0,>=2.7->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.4->mistral_inference)\n",
            "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests>=2.0.0->mistral_common>=1.5.4->mistral_inference) (2024.12.14)\n",
            "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.8.0->xformers>=0.0.24->mistral_inference)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading mistral_inference-1.6.0-py3-none-any.whl (32 kB)\n",
            "Using cached fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Using cached mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Using cached simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m145.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m139.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m166.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m138.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
            "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
            "Downloading numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m161.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pydantic_extra_types-2.10.5-py3-none-any.whl (38 kB)\n",
            "Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rpds_py-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-inspection, triton, termcolor, sympy, safetensors, rpds-py, regex, pydantic-core, pycountry, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, docstring-parser, attrs, annotated-types, tiktoken, simple-parsing, referencing, pydantic, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, fire, pydantic-extra-types, nvidia-cusolver-cu12, jsonschema-specifications, torch, jsonschema, xformers, mistral_common, mistral_inference\n",
            "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 attrs-25.3.0 docstring-parser-0.17.0 fire-0.7.1 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 mistral_common-1.8.5 mistral_inference-1.6.0 mpmath-1.3.0 networkx-3.5 numpy-2.3.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pillow-11.3.0 pycountry-24.6.1 pydantic-2.11.9 pydantic-core-2.33.2 pydantic-extra-types-2.10.5 referencing-0.36.2 regex-2025.9.18 rpds-py-0.27.1 safetensors-0.6.2 simple-parsing-0.1.7 sympy-1.14.0 termcolor-3.1.0 tiktoken-0.11.0 torch-2.8.0 triton-3.4.0 typing-inspection-0.4.1 xformers-0.0.32.post2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "3166926ed6b34800bb99ba0dd3392bb3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install mistral_inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/test_ultra.zip /content/test_ultra"
      ],
      "metadata": {
        "id": "gCTm11hg8DF5",
        "outputId": "3335dc48-441c-4e88-8e3e-600f9161c812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/test_ultra/ (stored 0%)\n",
            "  adding: content/test_ultra/args.yaml (deflated 46%)\n",
            "  adding: content/test_ultra/checkpoints/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/ (stored 0%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/tokenizer.model.v3 (deflated 61%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/params.json (deflated 49%)\n",
            "  adding: content/test_ultra/checkpoints/checkpoint_000200/consolidated/lora.safetensors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-xLs2Ot9-il",
        "outputId": "f0c6f171-b14c-4d0c-d5e9-cb24a7f07653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine learning is a subset of artificial intelligence that involves the use of algorithms to learn from data and make predictions or decisions without being explicitly programmed. It is a type of computer science that enables machines to learn and improve from experience without being explicitly programmed. Machine learning algorithms can learn from data and make predictions or decisions based\n"
          ]
        }
      ],
      "source": [
        "from mistral_inference.transformer import Transformer\n",
        "from mistral_inference.generate import generate\n",
        "\n",
        "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
        "from mistral_common.protocol.instruct.messages import UserMessage\n",
        "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
        "\n",
        "\n",
        "tokenizer = MistralTokenizer.from_file(\"/content/mistral_models/tokenizer.model.v3\")  # change to extracted tokenizer file\n",
        "model = Transformer.from_folder(\"/content/mistral_models\")  # change to extracted model dir\n",
        "model.load_lora(\"/content/test_ultra/checkpoints/checkpoint_000100/consolidated/lora.safetensors\")\n",
        "\n",
        "completion_request = ChatCompletionRequest(messages=[UserMessage(content=\"Explain Machine Learning to me in a nutshell.\")])\n",
        "\n",
        "tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
        "\n",
        "out_tokens, _ = generate([tokens], model, max_tokens=64, temperature=0.0, eos_id=tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
        "result = tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd8A8JP4Fx3C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8ccf8776754f4937b8a4230bc8325fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_ed38a985a29449e68a201616d033ebbe"
          }
        },
        "14bc19491d7d4fcb9f2c3bc95944dd7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d0aa48ea3114a6f9aad34452438182c",
            "placeholder": "​",
            "style": "IPY_MODEL_de210456e2704f108ff3ddc47838d703",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "482c5d4b7e824780909d85c5ecf616a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_331642fa2e07496688817d161d8aa31d",
            "placeholder": "​",
            "style": "IPY_MODEL_f7461f869ce443e0a2266c57afdbc5e2",
            "value": ""
          }
        },
        "abc61d5f8ea44549b2daa50268140fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f205dd0ec7b94514ba52c1838971a365",
            "style": "IPY_MODEL_e7bae007a6294259b929a006856bd25b",
            "value": true
          }
        },
        "9fb91b3e1c8f463db6bb8c548ce81aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_094fc700d0994f02a307ea38b2e1925b",
            "style": "IPY_MODEL_962dccf4f4e742edb6ce0fb9b69bd4d0",
            "tooltip": ""
          }
        },
        "bcf48d297262447c9cd7126ee8f3816e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5379d02eba1a42509f5f0b7b575ae74f",
            "placeholder": "​",
            "style": "IPY_MODEL_946108e7328944a8990de29a309904b8",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ed38a985a29449e68a201616d033ebbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7d0aa48ea3114a6f9aad34452438182c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de210456e2704f108ff3ddc47838d703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331642fa2e07496688817d161d8aa31d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7461f869ce443e0a2266c57afdbc5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f205dd0ec7b94514ba52c1838971a365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7bae007a6294259b929a006856bd25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "094fc700d0994f02a307ea38b2e1925b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962dccf4f4e742edb6ce0fb9b69bd4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5379d02eba1a42509f5f0b7b575ae74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946108e7328944a8990de29a309904b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d6170202c6449c68344d158ba39a46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa9e9ce6be94866a2df009454284fc4",
            "placeholder": "​",
            "style": "IPY_MODEL_8a70b545019741c4b609bb2549b166f6",
            "value": "Connecting..."
          }
        },
        "8aa9e9ce6be94866a2df009454284fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a70b545019741c4b609bb2549b166f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cbdd13e42eb4b24901b34daa35579d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d939c98fd35341feaf9b54f338c7e116",
              "IPY_MODEL_1c390daf5de54dd486cd57f075e4a803",
              "IPY_MODEL_abbb8610e3e94b0094017a261640ed72"
            ],
            "layout": "IPY_MODEL_05d9c314b87d4a85bba18570fea8c43c"
          }
        },
        "d939c98fd35341feaf9b54f338c7e116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3951c9a437164b9cb9ae5e2e661efd3c",
            "placeholder": "​",
            "style": "IPY_MODEL_37481e02e5544ff2bc42b6ba4b8579c4",
            "value": "Fetching 3 files: 100%"
          }
        },
        "1c390daf5de54dd486cd57f075e4a803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc6b016079e4bb8934665a0ebce5da1",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ed53cdaac04ac5b1a1d7795f585156",
            "value": 3
          }
        },
        "abbb8610e3e94b0094017a261640ed72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e041cfae81a447809351d5d4aa30b973",
            "placeholder": "​",
            "style": "IPY_MODEL_3ca3ca5dc3b64700ae6b54e6d565bc84",
            "value": " 3/3 [01:33&lt;00:00, 93.67s/it]"
          }
        },
        "05d9c314b87d4a85bba18570fea8c43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3951c9a437164b9cb9ae5e2e661efd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37481e02e5544ff2bc42b6ba4b8579c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc6b016079e4bb8934665a0ebce5da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ed53cdaac04ac5b1a1d7795f585156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e041cfae81a447809351d5d4aa30b973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca3ca5dc3b64700ae6b54e6d565bc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e7c56ce480a47e987adb0e913c3cd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f544f40ba5a14358b279ce6dbf2b67e5",
              "IPY_MODEL_504dca74e6ef4bb3b9314952347f2874",
              "IPY_MODEL_1342d9c5693649229012295c0f859902"
            ],
            "layout": "IPY_MODEL_f7bd4eac261a49dca47263e10753b84e"
          }
        },
        "f544f40ba5a14358b279ce6dbf2b67e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9f1b33f30240af8bf1178640e1127e",
            "placeholder": "​",
            "style": "IPY_MODEL_4bd042c4b7e74eb39539c2347974368f",
            "value": "params.json: 100%"
          }
        },
        "504dca74e6ef4bb3b9314952347f2874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee4ea8952e614cfea1e2b87725cb6377",
            "max": 202,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baa3dabbd8384f71a8376d64930ff601",
            "value": 202
          }
        },
        "1342d9c5693649229012295c0f859902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e6714014f142519e9faa2d579240a6",
            "placeholder": "​",
            "style": "IPY_MODEL_8b53afb33a1c406590842924f313ea6f",
            "value": " 202/202 [00:00&lt;00:00, 20.7kB/s]"
          }
        },
        "f7bd4eac261a49dca47263e10753b84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9f1b33f30240af8bf1178640e1127e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd042c4b7e74eb39539c2347974368f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee4ea8952e614cfea1e2b87725cb6377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa3dabbd8384f71a8376d64930ff601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71e6714014f142519e9faa2d579240a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b53afb33a1c406590842924f313ea6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1b28c6cb314705a313cbf28a665984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79a96b0a1dbc42aaa669a9b01bd774f9",
              "IPY_MODEL_5f4b6de0eb97442483007ceedda57acb",
              "IPY_MODEL_ee30256d7d9c4f1582436469588b74a1"
            ],
            "layout": "IPY_MODEL_ccee5afd802248a2ba2633e72d2230db"
          }
        },
        "79a96b0a1dbc42aaa669a9b01bd774f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdfde06a27c4fb9b4982147f17205fe",
            "placeholder": "​",
            "style": "IPY_MODEL_ee83fff097b645abb718cc04a8686c54",
            "value": "consolidated.safetensors: 100%"
          }
        },
        "5f4b6de0eb97442483007ceedda57acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcf283289be8497e93837372078f3730",
            "max": 14496078512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc950b5a34ec438fba0e499a6ef17a20",
            "value": 14496078512
          }
        },
        "ee30256d7d9c4f1582436469588b74a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1812749ee8148c8a70890d29522e714",
            "placeholder": "​",
            "style": "IPY_MODEL_5e068267eec04b41b3c38586cd5bcab6",
            "value": " 14.5G/14.5G [01:33&lt;00:00, 160MB/s]"
          }
        },
        "ccee5afd802248a2ba2633e72d2230db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfdfde06a27c4fb9b4982147f17205fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee83fff097b645abb718cc04a8686c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcf283289be8497e93837372078f3730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc950b5a34ec438fba0e499a6ef17a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1812749ee8148c8a70890d29522e714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e068267eec04b41b3c38586cd5bcab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fa22f3d8f0b4547a501822a968f22c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_904f5fe937de482db6c0085e6040d038",
              "IPY_MODEL_d9579af5e10149cb90a5c9ec5008d548",
              "IPY_MODEL_afb85edce74e40559c21a4e834fc93d7"
            ],
            "layout": "IPY_MODEL_000b3a0acedf4c48a163ad6df46052f5"
          }
        },
        "904f5fe937de482db6c0085e6040d038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03be5d7298b34a30b9eac04188ae1959",
            "placeholder": "​",
            "style": "IPY_MODEL_29ef33bf22cc4cd9ab093ab3e7f45825",
            "value": "tokenizer.model.v3: 100%"
          }
        },
        "d9579af5e10149cb90a5c9ec5008d548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8ac25b7c4748cb9ea3db64f2a8cdc9",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_864311f675dd4e19844869d4dfeac5f0",
            "value": 587404
          }
        },
        "afb85edce74e40559c21a4e834fc93d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465507aeaf3547c58be7fefdc8175b58",
            "placeholder": "​",
            "style": "IPY_MODEL_3c2da21314ae41eabd175581dc1e3a8d",
            "value": " 587k/587k [00:00&lt;00:00, 8.98MB/s]"
          }
        },
        "000b3a0acedf4c48a163ad6df46052f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03be5d7298b34a30b9eac04188ae1959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ef33bf22cc4cd9ab093ab3e7f45825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a8ac25b7c4748cb9ea3db64f2a8cdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864311f675dd4e19844869d4dfeac5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "465507aeaf3547c58be7fefdc8175b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c2da21314ae41eabd175581dc1e3a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}